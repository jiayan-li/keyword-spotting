{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F  \n",
    "from DNN_utils import (flatten) \n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "\n",
    "import numpy as np \n",
    "import mfcc_label \n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('processed_data/dnn_never_train.csv')\n",
    "\n",
    "if isinstance(df_train.iloc[0]['mfcc'], str):\n",
    "    df_train['mfcc'] = df_train['mfcc'].apply(lambda x: np.fromstring(x[1:-1], sep=' '))\n",
    "if isinstance(df_train.iloc[0]['label'], str):\n",
    "    df_train['label'] = df_train['label'].apply(lambda x: np.fromstring(x[1:-1], sep=' '))\n",
    "\n",
    "\n",
    "# Configurations \n",
    "NUM_TRAIN = int(0.8*len(df_train)) # Number of training examples for splitting training and validation datasets. \n",
    "NUM_ROWS = len(df_train)\n",
    "device = 'cpu'\n",
    "dtype = torch.float32\n",
    "print_every = 50\n",
    "\n",
    "# DNN Architecture Hyperparameters\n",
    "minibatch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15493, 3)\n",
      "(17249, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('processed_data/dnn_never_train.csv')\n",
    "df_test = pd.read_csv('processed_data/dnn_never_test.csv')\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "from joblib import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('timit/data/TRAIN/DR7/MSES0/SI2216.WAV',\n",
       "  'timit/data/TRAIN/DR7/MSES0/SI2216.PHN'),\n",
       " ('timit/data/TRAIN/DR1/MJEB1/SI2097.WAV',\n",
       "  'timit/data/TRAIN/DR1/MJEB1/SI2097.PHN'),\n",
       " ('timit/data/TRAIN/DR8/FMBG0/SX440.WAV',\n",
       "  'timit/data/TRAIN/DR8/FMBG0/SX440.PHN'),\n",
       " ('timit/data/TRAIN/DR4/FLKM0/SX440.WAV',\n",
       "  'timit/data/TRAIN/DR4/FLKM0/SX440.PHN'),\n",
       " ('timit/data/TRAIN/DR6/MSAT1/SI1703.WAV',\n",
       "  'timit/data/TRAIN/DR6/MSAT1/SI1703.PHN'),\n",
       " ('timit/data/TRAIN/DR7/FLEH0/SX61.WAV',\n",
       "  'timit/data/TRAIN/DR7/FLEH0/SX61.PHN'),\n",
       " ('timit/data/TRAIN/DR5/FBMH0/SX146.WAV',\n",
       "  'timit/data/TRAIN/DR5/FBMH0/SX146.PHN'),\n",
       " ('timit/data/TRAIN/DR7/FKDE0/SX61.WAV',\n",
       "  'timit/data/TRAIN/DR7/FKDE0/SX61.PHN'),\n",
       " ('timit/data/TEST/DR1/MDAB0/SI1039.WAV',\n",
       "  'timit/data/TEST/DR1/MDAB0/SI1039.PHN'),\n",
       " ('timit/data/TRAIN/DR4/MGAG0/SX61.WAV',\n",
       "  'timit/data/TRAIN/DR4/MGAG0/SX61.PHN'),\n",
       " ('timit/data/TEST/DR3/MCSH0/SI2179.WAV',\n",
       "  'timit/data/TEST/DR3/MCSH0/SI2179.PHN'),\n",
       " ('timit/data/TRAIN/DR3/MDBB1/SX376.WAV',\n",
       "  'timit/data/TRAIN/DR3/MDBB1/SX376.PHN'),\n",
       " ('timit/data/TRAIN/DR5/FCDR1/SX376.WAV',\n",
       "  'timit/data/TRAIN/DR5/FCDR1/SX376.PHN'),\n",
       " ('timit/data/TRAIN/DR3/MDWM0/SX376.WAV',\n",
       "  'timit/data/TRAIN/DR3/MDWM0/SX376.PHN'),\n",
       " ('timit/data/TRAIN/DR4/MCSS0/SX210.WAV',\n",
       "  'timit/data/TRAIN/DR4/MCSS0/SX210.PHN'),\n",
       " ('timit/data/TRAIN/DR3/MRJB1/SX210.WAV',\n",
       "  'timit/data/TRAIN/DR3/MRJB1/SX210.PHN'),\n",
       " ('timit/data/TRAIN/DR5/MJDM0/SX440.WAV',\n",
       "  'timit/data/TRAIN/DR5/MJDM0/SX440.PHN'),\n",
       " ('timit/data/TEST/DR5/MBPM0/SI1584.WAV',\n",
       "  'timit/data/TEST/DR5/MBPM0/SI1584.PHN'),\n",
       " ('timit/data/TRAIN/DR3/MTJM0/SX146.WAV',\n",
       "  'timit/data/TRAIN/DR3/MTJM0/SX146.PHN'),\n",
       " ('timit/data/TRAIN/DR4/MKAM0/SX146.WAV',\n",
       "  'timit/data/TRAIN/DR4/MKAM0/SX146.PHN'),\n",
       " ('timit/data/TRAIN/DR3/FEME0/SX425.WAV',\n",
       "  'timit/data/TRAIN/DR3/FEME0/SX425.PHN'),\n",
       " ('timit/data/TRAIN/DR3/FJLR0/SX61.WAV',\n",
       "  'timit/data/TRAIN/DR3/FJLR0/SX61.PHN'),\n",
       " ('timit/data/TRAIN/DR2/FPJF0/SX146.WAV',\n",
       "  'timit/data/TRAIN/DR2/FPJF0/SX146.PHN'),\n",
       " ('timit/data/TRAIN/DR2/FHLM0/SX210.WAV',\n",
       "  'timit/data/TRAIN/DR2/FHLM0/SX210.PHN'),\n",
       " ('timit/data/TRAIN/DR7/MDLC1/SI2065.WAV',\n",
       "  'timit/data/TRAIN/DR7/MDLC1/SI2065.PHN'),\n",
       " ('timit/data/TRAIN/DR8/MRDM0/SX425.WAV',\n",
       "  'timit/data/TRAIN/DR8/MRDM0/SX425.PHN'),\n",
       " ('timit/data/TRAIN/DR5/MSDH0/SX440.WAV',\n",
       "  'timit/data/TRAIN/DR5/MSDH0/SX440.PHN'),\n",
       " ('timit/data/TRAIN/DR5/FGMB0/SX425.WAV',\n",
       "  'timit/data/TRAIN/DR5/FGMB0/SX425.PHN'),\n",
       " ('timit/data/TRAIN/DR4/FALR0/SX425.WAV',\n",
       "  'timit/data/TRAIN/DR4/FALR0/SX425.PHN')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load('processed_data/train_test_dataset_never.joblib')['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 11])\n"
     ]
    }
   ],
   "source": [
    "class DNN_FC(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        # assign layer objects to class attributes\n",
    "        # We may write a loop if we use the same activation function for all layers.\n",
    "        self.fc1 = nn.Linear(input_size, input_size)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(input_size, input_size)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight) \n",
    "        self.fc3 = nn.Linear(input_size, input_size)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight)\n",
    "        self.fc4 = nn.Linear(input_size, input_size)\n",
    "        nn.init.kaiming_normal_(self.fc4.weight)\n",
    "        self.fc5 = nn.Linear(input_size, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc5.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_temp = x\n",
    "        x_temp = flatten(x_temp)\n",
    "        x_temp = F.relu(self.fc1(x_temp))\n",
    "        x_temp = F.relu(self.fc2(x_temp))\n",
    "        x_temp = F.relu(self.fc3(x_temp))\n",
    "        x_temp = F.relu(self.fc4(x_temp))\n",
    "        scores = self.fc5(x_temp)\n",
    "        return scores\n",
    "\n",
    "\n",
    "def test_DNN_FC():\n",
    "    input_size = 20  # Feature dimension for mfcc\n",
    "    num_classes = 11 # Number of phoneme classes\n",
    "    dtype = torch.float32\n",
    "    x = torch.zeros((minibatch_size, input_size), dtype=dtype)  # minibatch size 64, feature dimension 20\n",
    "    model = DNN_FC(input_size, num_classes)\n",
    "    scores = model(x)\n",
    "    print(scores.size())  # you should see [minibatch_size, num_classes]\n",
    "test_DNN_FC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc</th>\n",
       "      <th>label</th>\n",
       "      <th>state_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-730.505798, 45.0450668, -24.2304726, -16.595...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>{'h#': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-714.74677, 51.683174, -20.392345, -13.274165...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>{'h#': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-720.12866, 46.353207, -18.542915, -15.895822...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>{'h#': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-726.85284, 38.16919, -21.354225, -16.98072, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>{'h#': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-733.83295, 39.958935, -22.630146, -19.272156...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>{'h#': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15488</th>\n",
       "      <td>[-773.1762, 4.0019016, 2.5322413, 2.8646927, 3...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>{'h#': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15489</th>\n",
       "      <td>[-773.2592, 4.076532, 2.7111504, 3.3019888, 4....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>{'h#': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15490</th>\n",
       "      <td>[-774.35565, 3.5023093, 3.4348507, 3.9783638, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>{'h#': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15491</th>\n",
       "      <td>[-774.29865, 4.247159, 3.8669136, 3.643158, 3....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>{'h#': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15492</th>\n",
       "      <td>[-774.073, 4.307059, 4.27923, 4.0476756, 3.220...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>{'h#': 1.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15493 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mfcc  \\\n",
       "0      [-730.505798, 45.0450668, -24.2304726, -16.595...   \n",
       "1      [-714.74677, 51.683174, -20.392345, -13.274165...   \n",
       "2      [-720.12866, 46.353207, -18.542915, -15.895822...   \n",
       "3      [-726.85284, 38.16919, -21.354225, -16.98072, ...   \n",
       "4      [-733.83295, 39.958935, -22.630146, -19.272156...   \n",
       "...                                                  ...   \n",
       "15488  [-773.1762, 4.0019016, 2.5322413, 2.8646927, 3...   \n",
       "15489  [-773.2592, 4.076532, 2.7111504, 3.3019888, 4....   \n",
       "15490  [-774.35565, 3.5023093, 3.4348507, 3.9783638, ...   \n",
       "15491  [-774.29865, 4.247159, 3.8669136, 3.643158, 3....   \n",
       "15492  [-774.073, 4.307059, 4.27923, 4.0476756, 3.220...   \n",
       "\n",
       "                                                   label state_weights  \n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   {'h#': 1.0}  \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   {'h#': 1.0}  \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   {'h#': 1.0}  \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   {'h#': 1.0}  \n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   {'h#': 1.0}  \n",
       "...                                                  ...           ...  \n",
       "15488  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   {'h#': 1.0}  \n",
       "15489  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   {'h#': 1.0}  \n",
       "15490  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   {'h#': 1.0}  \n",
       "15491  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   {'h#': 1.0}  \n",
       "15492  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   {'h#': 1.0}  \n",
       "\n",
       "[15493 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(type(df_train.iloc[0]['label']))\n",
    "# If the type is str, convert it\n",
    "\n",
    "display(df_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#mfcc = df_train.iloc[0:5]['mfcc']\n",
    "#mfcc = np.vstack(mfcc)\n",
    "#mfcc \n",
    "\n",
    "\n",
    "labels = df_train.iloc[0:5]['label']\n",
    "labels = np.vstack(labels)\n",
    "display(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-7.3051e+02,  4.5045e+01, -2.4230e+01, -1.6596e+01,  7.8798e+00,\n",
       "           6.0388e-01, -1.2444e+01,  1.5479e+00,  1.8096e+01,  1.0397e+01,\n",
       "           9.5008e-01,  6.5883e+00,  1.3456e+01,  4.3042e+00, -9.5567e+00,\n",
       "          -5.4092e+00,  2.0956e+00,  1.1521e+00,  4.0445e+00,  4.9519e+00],\n",
       "         [-7.1475e+02,  5.1683e+01, -2.0392e+01, -1.3274e+01, -3.0518e+00,\n",
       "          -3.8946e+00, -7.8653e+00,  4.2943e+00,  1.9027e+01,  5.3817e+00,\n",
       "          -7.3529e+00,  3.3265e+00,  9.8732e+00,  4.8012e+00, -1.0586e+01,\n",
       "          -8.3340e+00,  1.0399e+01,  1.2690e+01,  1.1761e+01,  8.7251e+00],\n",
       "         [-7.2013e+02,  4.6353e+01, -1.8543e+01, -1.5896e+01, -1.6697e+01,\n",
       "          -6.0928e+00, -1.3419e+00,  5.4095e+00,  2.1859e+01,  5.5194e+00,\n",
       "          -1.4134e+01,  5.9534e-01,  9.5893e+00,  5.5199e+00, -6.0089e+00,\n",
       "          -5.3524e+00,  1.0020e+01,  1.4292e+01,  1.3084e+01,  5.8263e+00],\n",
       "         [-7.2685e+02,  3.8169e+01, -2.1354e+01, -1.6981e+01, -1.2307e+01,\n",
       "          -1.3834e+00, -1.4019e+00,  6.3001e+00,  2.7746e+01,  1.1269e+01,\n",
       "          -1.0486e+01,  4.7258e+00,  9.7506e+00,  5.9056e+00, -5.1041e+00,\n",
       "          -2.1838e+00,  6.9739e+00,  1.0429e+01,  1.2742e+01,  9.5931e+00],\n",
       "         [-7.3383e+02,  3.9959e+01, -2.2630e+01, -1.9272e+01, -8.4695e-01,\n",
       "           6.8247e+00,  1.1924e+00,  1.3461e+01,  2.9216e+01,  3.6541e+00,\n",
       "          -1.4534e+01,  2.3607e+00,  8.8360e+00,  4.5712e-01, -7.8657e+00,\n",
       "          -2.6887e+00,  6.6100e+00,  7.1146e+00,  7.7449e+00,  8.8961e+00]]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert dataset into a format that torch can read.\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, train=True):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the rows that are selected by the idx.\n",
    "        mfcc = self.df.iloc[idx]['mfcc']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "\n",
    "        # Stack the rows for mfcc and label.\n",
    "        # Stack a list of (1,n) dimensional np.ndarrays into (m,n) dimensional np.ndarray. \n",
    "        mfcc = np.vstack(mfcc)\n",
    "        label = np.vstack(label)\n",
    "\n",
    "        # Convert 2 dimensional np.ndarrays into torch tensors.\n",
    "        mfcc = torch.tensor(mfcc, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        if self.transform:\n",
    "            mfcc = self.transform(mfcc)\n",
    "\n",
    "        return mfcc, label\n",
    "\n",
    "# Create an instance of your dataset with your DataFrame\n",
    "dataset_train = CustomDataset(df_train,train=True)  # Assuming df is your pandas DataFrame\n",
    "\n",
    "# Create the DataLoader to handle batching\n",
    "loader_train = DataLoader(dataset_train, batch_size=minibatch_size,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "display(dataset_train.__getitem__(range(5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Features (MFCCs) size: torch.Size([512, 20, 1])\n",
      "Labels size: torch.Size([512, 14, 1])\n",
      "\n",
      "\n",
      "Batch 2\n",
      "Features (MFCCs) size: torch.Size([512, 20, 1])\n",
      "Labels size: torch.Size([512, 14, 1])\n",
      "\n",
      "\n",
      "Batch 3\n",
      "Features (MFCCs) size: torch.Size([512, 20, 1])\n",
      "Labels size: torch.Size([512, 14, 1])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example code to print the contents of the first few batches in loader_train\n",
    "for i, (inputs, labels) in enumerate(loader_train):\n",
    "    print(f\"Batch {i + 1}\")\n",
    "    print(\"Features (MFCCs) size:\", inputs.size())\n",
    "    print(\"Labels size:\", labels.size())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Optional: Stop after a few batches to avoid flooding the output\n",
    "    if i == 2:  # Adjust this number based on how many batches you want to see\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            y = flatten(y) # Flatten y to convert dimension from (Nx1) to (N,)\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=dtype) \n",
    "            scores = model(x) \n",
    "            _, preds = scores.max(1) \n",
    "            true_class = y.argmax(dim=1) # True class is the one that has the highest probability in the data.\n",
    "            num_correct += (preds == true_class).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return acc \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "dtype = torch.float32\n",
    "\n",
    "def train(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train the model using the PyTorch Module API.\n",
    "\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "\n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    accuracy_val_lst = []\n",
    "    accuracy_cal_max = 0\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            y = flatten(y) # Flatten y to convert the dimension from (Nx1) to (N,)\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "\n",
    "            scores = model(x)\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            loss = criterion(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                print()\n",
    "                accuracy_val = check_accuracy(loader_val, model)\n",
    "                if accuracy_val > accuracy_cal_max:\n",
    "                    accuracy_cal_max = accuracy_val\n",
    "                    model_params = model.state_dict()\n",
    "                accuracy_val_lst.append((t,accuracy_val))\n",
    "        \n",
    "    print('Training is complete. Accuracies on the validation set are:') \n",
    "    print(accuracy_val_lst)\n",
    "    return \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 67.7302\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 4 / 3099 correct (0.13)\n",
      "Iteration 0, loss = 0.3093\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 2076 / 3099 correct (66.99)\n",
      "Iteration 0, loss = 0.1267\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 2100 / 3099 correct (67.76)\n",
      "Iteration 0, loss = 0.0986\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 2098 / 3099 correct (67.70)\n",
      "Iteration 0, loss = 0.0991\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 2107 / 3099 correct (67.99)\n",
      "Iteration 0, loss = 0.1014\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 2090 / 3099 correct (67.44)\n",
      "Iteration 0, loss = 0.0846\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 2211 / 3099 correct (71.35)\n",
      "Iteration 0, loss = 0.0882\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 2237 / 3099 correct (72.18)\n",
      "Iteration 0, loss = 0.0749\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 2253 / 3099 correct (72.70)\n",
      "Iteration 0, loss = 0.0817\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 2249 / 3099 correct (72.57)\n",
      "Training is complete. Accuracies on the validation set are:\n",
      "[(0, 0.0012907389480477573), (0, 0.6698935140367861), (0, 0.6776379477250726), (0, 0.6769925782510487), (0, 0.6798967408841562), (0, 0.6744111003549532), (0, 0.7134559535333979), (0, 0.7218457566957083), (0, 0.7270087124878993), (0, 0.7257179735398516)]\n"
     ]
    }
   ],
   "source": [
    "input_size = len(df_train['mfcc'][0])\n",
    "num_classes = len(df_train['label'][0])\n",
    "learning_rate = 1e-2\n",
    "model = DNN_FC(input_size, num_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train(model, optimizer,epochs = 10) \n",
    "\n",
    "# Accuracy on the validation set: 72.57%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            y = flatten(y) # Flatten y to convert dimension from (Nx1) to (N,)\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=dtype) \n",
    "            scores = model(x) \n",
    "            _, preds = scores.max(1) \n",
    "            true_class = y.argmax(dim=1) # True class is the one that has the highest probability in the data.\n",
    "            num_correct += (preds == true_class).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return acc \n",
    "\n",
    "\n",
    "# File id: Keep path of the audio file, and probabilities with size (num_frames, num_classes).  \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
