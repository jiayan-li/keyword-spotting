{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/philipperemy/timit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/mfekadu/darpa-timit-acousticphonetic-continuous-speech?resource=download\n",
    "\n",
    "https://www.kaggle.com/code/julwan/phoneme-recognition-with-wav2vec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wav2vec seems like a common transformer model for speech recognition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "630 speakers, each read 10 sentences—2 dialect \"shibboleth\" sentences (SA), 5 phonetically compact sentences (SX), and 3 phonetically diverse sentences (SI).\n",
    "\n",
    "- SA: expose the dialectal variants of the speakers.\n",
    "- SX: provide a good coverage of pairs of phones, with extra occurrences of phonetic contexts thought to be either difficult or of particular interest.\n",
    "- SI: add diversity in sentence types and phonetic contexts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Sentence Type | #Sentences | #Speakers | Total | #Sentences/Speaker |\n",
    "|---------------|------------|-----------|-------|--------------------|\n",
    "| Dialect (SA)  |      2     |    630    | 1260  |         2          |\n",
    "| Compact (SX)  |     450    |     7     | 3150  |         5          |\n",
    "| Diverse (SI)  |    1890    |     1     | 1890  |         3          |\n",
    "|---------------|------------|-----------|-------|--------------------|\n",
    "| Total         |    2342    |           | 6300  |        10          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Dialect Region (dr) | #Male   | #Female  | Total   |\n",
    "|----------------------|---------|----------|---------|\n",
    "|         1            | 31 (63%)| 18 (27%) | 49 (8%) |\n",
    "|         2            | 71 (70%)| 31 (30%) |102(16%)|\n",
    "|         3            | 79 (67%)| 23 (23%) |102(16%)|\n",
    "|         4            | 69 (69%)| 31 (31%) |100(16%)|\n",
    "|         5            | 62 (63%)| 36 (37%) | 98(16%)|\n",
    "|         6            | 30 (65%)| 16 (35%) | 46 (7%)|\n",
    "|         7            | 74 (74%)| 26 (26%) |100(16%)|\n",
    "|         8            | 22 (67%)| 11 (33%) | 33 (5%)|\n",
    "|----------------------|---------|----------|---------|\n",
    "|        Total         | 438(70%)|192(30%)  |630(100%)|\n",
    "\n",
    "The dialect regions are:\n",
    "   dr1: New England\n",
    "   dr2: Northern\n",
    "   dr3: North Midland\n",
    "   dr4: South Midland\n",
    "   dr5: Southern\n",
    "   dr6: New York City\n",
    "   dr7: Western\n",
    "   dr8: Army Brat (moved around)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each utterance, the following information is available:\n",
    "- .wav file: the speech waveform.\n",
    "- .phn file: Time-aligned phonetic transcription.\n",
    "- .wrd file: Time-aligned word transcription.\n",
    "- .txt file: Associated orthographic transcription of the words the\n",
    "            person said."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# custum modules\n",
    "from mfcc_label import *\n",
    "from utils import *\n",
    "from config import TEST_PHN_PATH\n",
    "from get_prob import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load phoneme, word, and transcript data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timit/data/TRAIN/DR4/MGAG0/SX61.TXT',\n",
       " 'timit/data/TRAIN/DR4/MGAG0/SX61.WAV',\n",
       " 'timit/data/TRAIN/DR4/MGAG0/SX61.PHN',\n",
       " 'timit/data/TRAIN/DR4/MGAG0/SX61.WRD',\n",
       " 'timit/data/TRAIN/DR4/MGAG0/SX61.WAV.wav']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sx61\n",
    "glob.glob('timit/data/TRAIN/DR4/MGAG0/SX61.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_sample</th>\n",
       "      <th>end_sample</th>\n",
       "      <th>phoneme</th>\n",
       "      <th>diff_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>36940</td>\n",
       "      <td>39000</td>\n",
       "      <td>#b</td>\n",
       "      <td>2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>39000</td>\n",
       "      <td>40200</td>\n",
       "      <td>#b</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>40200</td>\n",
       "      <td>40960</td>\n",
       "      <td>#b</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>40960</td>\n",
       "      <td>41720</td>\n",
       "      <td>#b</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>41720</td>\n",
       "      <td>43680</td>\n",
       "      <td>h#</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_sample  end_sample phoneme  diff_sample\n",
       "32         36940       39000      #b         2060\n",
       "33         39000       40200      #b         1200\n",
       "34         40200       40960      #b          760\n",
       "35         40960       41720      #b          760\n",
       "36         41720       43680      h#         1960"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# phoneme\n",
    "df_phoneme = load_data(glob.glob('timit/data/TRAIN/DR4/MGAG0/SX61.PHN')[0], \"phoneme\")\n",
    "df_phoneme.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word\n",
    "df_word = load_data(glob.glob('timit/data/TRAIN/DR4/MGAG0/SX61.WRD')[0], \"word\")\n",
    "df_word.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcript = load_transcript('timit/data/TRAIN/DR4/MGAG0/SX61.TXT')\n",
    "df_transcript.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC\n",
    "Note that we can always use smaller `win_length` and `hop_length` for more fine-grained alignment.\n",
    "\n",
    "if we choose 25ms window and 5ms hop, we can have $25 * 10^-3 * 16000 = 400$ `win_length` and $5 * 10^-3 * 16000 = 80$ `hop_length`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://librosa.org/doc/main/generated/librosa.feature.mfcc.html#librosa.feature.mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_sample</th>\n",
       "      <th>end_sample</th>\n",
       "      <th>mfcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>43280</td>\n",
       "      <td>43680</td>\n",
       "      <td>[-827.1031, 32.212986, 10.357775, 4.273916, -7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>43360</td>\n",
       "      <td>43760</td>\n",
       "      <td>[-833.8036, 18.833408, 6.527279, 11.398876, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>43440</td>\n",
       "      <td>43840</td>\n",
       "      <td>[-845.2821, 3.8058267, 1.8199315, 11.270794, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>43520</td>\n",
       "      <td>43920</td>\n",
       "      <td>[-847.30914, 4.7726836, 6.2668734, 6.074581, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>43600</td>\n",
       "      <td>44000</td>\n",
       "      <td>[-847.56964, 9.320388, 15.307094, 7.9442987, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     start_sample  end_sample  \\\n",
       "541         43280       43680   \n",
       "542         43360       43760   \n",
       "543         43440       43840   \n",
       "544         43520       43920   \n",
       "545         43600       44000   \n",
       "\n",
       "                                                  mfcc  \n",
       "541  [-827.1031, 32.212986, 10.357775, 4.273916, -7...  \n",
       "542  [-833.8036, 18.833408, 6.527279, 11.398876, 0....  \n",
       "543  [-845.2821, 3.8058267, 1.8199315, 11.270794, 5...  \n",
       "544  [-847.30914, 4.7726836, 6.2668734, 6.074581, 8...  \n",
       "545  [-847.56964, 9.320388, 15.307094, 7.9442987, 1...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 3)\n"
     ]
    }
   ],
   "source": [
    "df_mfcc = process_audio_file('timit/data/TRAIN/DR4/MGAG0/SX61.WAV',\n",
    "                             win_length=400, \n",
    "                             hop_length=80)\n",
    "display(df_mfcc.tail())\n",
    "\n",
    "print(df_mfcc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### draft/explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y: total number of samples\n",
    "\n",
    "sr: number of samples per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load('timit/data/TRAIN/DR4/MGAG0/SX61.WAV', sr=16000)\n",
    "y.shape, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load('timit/data/TRAIN/DR4/MGAG0/SX61.WAV')\n",
    "y.shape, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration\n",
    "60259/22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we know y=43725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_transcript('timit/data/TRAIN/DR4/MGAG0/SX61.TXT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try another \n",
    "y, sr = librosa.load('timit/data/TRAIN/DR4/MGAG0/SA1.WAV', sr=16000)\n",
    "y.shape, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_transcript('timit/data/TRAIN/DR4/MGAG0/SA1.TXT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples=Duration×Sampling frequency (Sr in Hz)\n",
    "# Hz represents the number of samples per second.\n",
    "duration = len(y) / sr\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "43725/duration  \n",
    "# if an audio file is 2.732834467120181 seconds long and contains 43725 samples, it means that the audio file has a sampling rate of approximately 16000 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 20  # Number of MFCC coefficients\n",
    "hop_length = 512  # Number of samples between consecutive frames (frame step)\n",
    "win_length = 1024  # Length of the analysis window in samples (frame size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1024/16000  # 64 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract MFCC features\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, win_length=win_length, n_mfcc=n_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs.shape\n",
    "# The first dimension (20) represents the number of MFCC coefficients extracted. This is a common default value, as 20 coefficients are often sufficient to capture relevant information about the spectral characteristics of the audio signal.\n",
    "# The second dimension (86) represents the number of frames extracted from the audio signal. The number of frames is determined by the duration of the audio signal and the frame length and hop length used in the feature extraction process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align df_mfcc and df_phoneme "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epi, pau, h# are silence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_sample</th>\n",
       "      <th>end_sample</th>\n",
       "      <th>phoneme</th>\n",
       "      <th>diff_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16510.000000</td>\n",
       "      <td>18046.000000</td>\n",
       "      <td>#b</td>\n",
       "      <td>1536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18046.000000</td>\n",
       "      <td>18680.000000</td>\n",
       "      <td>#b</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18680.000000</td>\n",
       "      <td>19173.333333</td>\n",
       "      <td>b-axr</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19173.333333</td>\n",
       "      <td>19666.666667</td>\n",
       "      <td>m-axr</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19666.666667</td>\n",
       "      <td>20160.000000</td>\n",
       "      <td>e-axr</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_sample    end_sample phoneme  diff_sample\n",
       "13  16510.000000  18046.000000      #b         1536\n",
       "14  18046.000000  18680.000000      #b          634\n",
       "15  18680.000000  19173.333333   b-axr         1480\n",
       "16  19173.333333  19666.666667   m-axr         1480\n",
       "17  19666.666667  20160.000000   e-axr         1480"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_phoneme = load_data(TEST_PHN_PATH, \"phoneme\")\n",
    "df_phoneme = split_phoneme(df_phoneme)\n",
    "display(df_phoneme[(df_phoneme['start_sample']>=16000) & (df_phoneme['end_sample']<=21000)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust display settings \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_mfcc = label_df_mfcc(df_mfcc, df_phoneme) \n",
    "new_df_mfcc[(df_mfcc['start_sample']>=16000) & (df_mfcc['end_sample']<=21000)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_mfcc2 = vectorize_label_df_mfcc(new_df_mfcc, df_phoneme)\n",
    "new_df_mfcc2[(new_df_mfcc2['start_sample']>=16000) & (new_df_mfcc2['end_sample']<=21000)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare DNN training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mfcc_label import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
