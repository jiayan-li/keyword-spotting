{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategies for training DNN:\n",
    "\n",
    "Upsampling strategies:\n",
    "\n",
    "1- Resample the minority classes such that in half of the data, one of the first 12 classes have positive probabilities (the other half has zero probabilities for the first 12 classes).\n",
    "\n",
    "2- Resample the minority classes such that each class has the same number of observations as class 14 (#b). \n",
    "\n",
    "3- Resample the minority classes such that each class has the same number of observations as class 13 (h#).\n",
    "\n",
    "Changing the objective function:\n",
    "\n",
    "1- KL divergence\n",
    "\n",
    "2- CrossEntropyLoss\n",
    "\n",
    "3- CrossEntropyLoss with weights given to 12 classes.\n",
    "\n",
    "3- Train with single class labels (rather than vectors).\n",
    "\n",
    "Changing the architecture:\n",
    "\n",
    "1- More layers or less layers.\n",
    "\n",
    "2- Relu or sigmoid activation functions.\n",
    "\n",
    "Chaning the data:\n",
    "\n",
    "1- Aggregate class labes (1 class per phoneme)\n",
    "\n",
    "Changing HMM\n",
    "\n",
    "1- Instead of highest probability path, calculate v_C(T) \n",
    "\n",
    "2- Try different window length (instead of 60 frames). Calculate v_C(T)/T to get a normalized score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F  \n",
    "import DNN_utils\n",
    "#from DNN_utils import (flatten, column_str_to_numpy, check_accuracy, check_loss, check_accuracy_12_classes)\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from joblib import load \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import helper functions.\n",
    "import mfcc_label \n",
    "import get_prob\n",
    "\n",
    "# Read the data\n",
    "df_train_val = pd.read_csv('processed_data/dnn_never_train.csv')\n",
    "df_test = pd.read_csv('processed_data/dnn_never_test.csv')\n",
    "\n",
    "# Some columns are recorded as string although they are arrays.\n",
    "DNN_utils.column_str_to_numpy(df_train_val, 'mfcc')\n",
    "DNN_utils.column_str_to_numpy(df_train_val, 'label')\n",
    "DNN_utils.column_str_to_numpy(df_test, 'mfcc')\n",
    "DNN_utils.column_str_to_numpy(df_test, 'label')\n",
    "\n",
    "#Split the train set into train and validation sets.\n",
    "df_train_pre, df_val = train_test_split(df_train_val, test_size=0.2, random_state=42)\n",
    "df_train_pre.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a single class label (type: int) which is the highest probability class in the label vector (type: 14x1 array).\n",
    "df_train_pre['single_class_label'] = df_train_pre['label'].apply(lambda x: np.argmax(x))\n",
    "df_val['single_class_label'] = df_val['label'].apply(lambda x: np.argmax(x))\n",
    "df_test['single_class_label'] = df_test['label'].apply(lambda x: np.argmax(x))\n",
    "\n",
    "# Configurations \n",
    "#NUM_TRAIN = int(0.8*len(df_train_pre)) # Number of training examples for splitting training and validation datasets. \n",
    "#NUM_ROWS = len(df_train_pre)\n",
    "device = DNN_utils.device\n",
    "dtype = DNN_utils.dtype\n",
    "\n",
    "# DNN Architecture Hyperparameters\n",
    "minibatch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15493\n",
      "12394\n",
      "3099\n",
      "17249\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train_val))\n",
    "print(len(df_train_pre))\n",
    "print(len(df_val)) \n",
    "print(len(df_test)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npd.set_option('display.max_colwidth', None)\\n\\n# Upsample from observations that give positive probability on one of the 12 classes that correspond to 'never'. \\ndef upsample_minority(df, mask):\\n    from sklearn.utils import resample\\n    df_minority = df[mask]\\n    df_majority = df[~mask]\\n\\n    df_minority_upsampled = resample(df_minority,\\n                                    replace=True,     # sample with replacement\\n                                    n_samples=len(df_majority),    # to match majority class\\n                                    random_state=42) # reproducible results\\n\\n    df_upsampled = pd.concat([df_majority, df_minority_upsampled])\\n    return df_upsampled\\n\\nmask = df_train_pre['label'].apply(lambda x: any(elem > 0 for elem in x[:12]))\\n#mask = df_train_pre['label'].apply(lambda x: all(elem == 0 for elem in x[12:]))\\ndf_train = upsample_minority(df_train_pre, mask)\\n\\nprint('Before upsampling:')\\ndisplay(df_train_pre['label'].apply(lambda x: any(elem > 0 for elem in x[:12])).value_counts()) \\n\\n# Display new class counts\\nprint('After upsampling:')\\ndisplay(df_train['label'].apply(lambda x: any(elem > 0 for elem in x[:12])).value_counts()) \\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Upsample from observations that give positive probability on one of the 12 classes that correspond to 'never'. \n",
    "def upsample_minority(df, mask):\n",
    "    from sklearn.utils import resample\n",
    "    df_minority = df[mask]\n",
    "    df_majority = df[~mask]\n",
    "\n",
    "    df_minority_upsampled = resample(df_minority,\n",
    "                                    replace=True,     # sample with replacement\n",
    "                                    n_samples=len(df_majority),    # to match majority class\n",
    "                                    random_state=42) # reproducible results\n",
    "\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "    return df_upsampled\n",
    "\n",
    "mask = df_train_pre['label'].apply(lambda x: any(elem > 0 for elem in x[:12]))\n",
    "#mask = df_train_pre['label'].apply(lambda x: all(elem == 0 for elem in x[12:]))\n",
    "df_train = upsample_minority(df_train_pre, mask)\n",
    "\n",
    "print('Before upsampling:')\n",
    "display(df_train_pre['label'].apply(lambda x: any(elem > 0 for elem in x[:12])).value_counts()) \n",
    "\n",
    "# Display new class counts\n",
    "print('After upsampling:')\n",
    "display(df_train['label'].apply(lambda x: any(elem > 0 for elem in x[:12])).value_counts()) \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc</th>\n",
       "      <th>label</th>\n",
       "      <th>state_weights</th>\n",
       "      <th>single_class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-705.99225, 71.87973, 32.35219, 36.1934, 41.28257, 2.7530541, -1.9872639, 22.898275, -9.932304, -15.586997, -8.986916, -20.780283, -1.1563901, 4.5018673, -9.66007, -31.509727, 1.0515851, -8.567638, -3.725089, 8.328537]</td>\n",
       "      <td>[0.5575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4425]</td>\n",
       "      <td>{'#b': 0.4425, 'b-n': 0.5575}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-466.86948, 131.32242, -27.895485, -17.326698, -14.464546, 11.196297, -12.233515, -23.445066, -16.804337, 18.757277, 0.8819246, 1.260014, -5.4004154, 12.914358, -27.524231, 5.572198, -12.900546, -7.520482, -8.263817, 2.8675315]</td>\n",
       "      <td>[0.81916667, 0.18083333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>{'b-n': 0.8191666666666697, 'm-n': 0.1808333333333303}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-487.07132, 135.9779, -3.025653, -9.435239, -3.4786983, 1.6876291, -20.943718, -7.8202906, 14.812183, 8.936998, 15.624887, -38.165127, -3.2568831, 6.699148, 6.8093796, -13.3633795, -4.9855833, 6.2166805, -5.063633, 0.8156262]</td>\n",
       "      <td>[0.7725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2275]</td>\n",
       "      <td>{'#b': 0.2275, 'b-n': 0.7725}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-504.30026, 167.75624, -43.991325, -12.616833, 17.761126, -22.669508, -22.600502, -32.012856, -13.214453, 23.409264, -22.854027, -14.643912, 1.8293163, 5.0488992, -20.995512, -6.752759, -0.42442548, -4.7568603, -8.2071056, -18.368492]</td>\n",
       "      <td>[0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4]</td>\n",
       "      <td>{'#b': 0.4, 'b-n': 0.6}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-522.470398, 114.880325, -28.6871605, 60.610611, -33.066246, -22.5851097, -2.70186663, 11.0690565, -11.3093596, -39.6996803, -7.85373592, 0.471425563, -3.77920032, 1.12888217, -12.4821405, -17.5289898, 3.33738279, -5.42973566, -11.7449684, -10.3080702]</td>\n",
       "      <td>[0.58333333, 0.41666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>{'b-n': 0.5833333333333303, 'm-n': 0.4166666666666697}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32377</th>\n",
       "      <td>[-354.37424, 153.82423, 2.520186, 8.557072, -62.9833, -70.76247, 31.027435, -28.974052, -1.3362603, -6.622672, -28.985481, 6.8635836, -23.302856, 17.592358, 1.9556779, -8.322697, 1.6778979, -5.984693, -9.394501, -18.730194]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>{'#b': 1.0}</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32378</th>\n",
       "      <td>[-541.0925, -20.647453, -19.415312, -3.7550635, -25.011345, 7.143332, -16.555939, -10.724681, 13.894259, 10.9246235, -23.339613, -8.79563, 11.684788, 1.0004408, 9.840512, -4.0137005, 5.4408083, -1.9365463, -10.327684, 1.4280273]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>{'#b': 1.0}</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32379</th>\n",
       "      <td>[-361.39725, 200.15135, -11.198521, -74.57884, -26.557076, -30.454882, -26.454899, -23.900236, -6.9710026, 10.228376, -62.84133, 9.395352, -1.8819872, -2.3180122, 9.137184, -22.453075, 9.633455, -0.8796562, -26.236694, -2.5513773]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>{'#b': 1.0}</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32380</th>\n",
       "      <td>[-560.96643, 85.371414, -12.350075, -33.760818, -45.370388, 11.333093, -5.9454966, -0.63891798, 3.0575819, -33.63752, 20.533573, 1.9418074, 10.326906, 4.8501635, -0.17955418, -8.1675873, -6.8336906, 10.819086, -4.0187063, -1.4526093]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>{'#b': 1.0}</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32381</th>\n",
       "      <td>[-460.5466, 124.15584, -70.547966, -20.204004, -22.291546, -13.947313, -28.85445, -36.783035, 13.090644, -21.71759, -8.811714, -18.16044, -16.802431, 1.4008222, -27.485973, -12.374393, -11.544936, -19.798939, -9.840371, -13.991043]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>{'#b': 1.0}</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32382 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                mfcc  \\\n",
       "0                                        [-705.99225, 71.87973, 32.35219, 36.1934, 41.28257, 2.7530541, -1.9872639, 22.898275, -9.932304, -15.586997, -8.986916, -20.780283, -1.1563901, 4.5018673, -9.66007, -31.509727, 1.0515851, -8.567638, -3.725089, 8.328537]   \n",
       "1                               [-466.86948, 131.32242, -27.895485, -17.326698, -14.464546, 11.196297, -12.233515, -23.445066, -16.804337, 18.757277, 0.8819246, 1.260014, -5.4004154, 12.914358, -27.524231, 5.572198, -12.900546, -7.520482, -8.263817, 2.8675315]   \n",
       "2                                 [-487.07132, 135.9779, -3.025653, -9.435239, -3.4786983, 1.6876291, -20.943718, -7.8202906, 14.812183, 8.936998, 15.624887, -38.165127, -3.2568831, 6.699148, 6.8093796, -13.3633795, -4.9855833, 6.2166805, -5.063633, 0.8156262]   \n",
       "3                        [-504.30026, 167.75624, -43.991325, -12.616833, 17.761126, -22.669508, -22.600502, -32.012856, -13.214453, 23.409264, -22.854027, -14.643912, 1.8293163, 5.0488992, -20.995512, -6.752759, -0.42442548, -4.7568603, -8.2071056, -18.368492]   \n",
       "4      [-522.470398, 114.880325, -28.6871605, 60.610611, -33.066246, -22.5851097, -2.70186663, 11.0690565, -11.3093596, -39.6996803, -7.85373592, 0.471425563, -3.77920032, 1.12888217, -12.4821405, -17.5289898, 3.33738279, -5.42973566, -11.7449684, -10.3080702]   \n",
       "...                                                                                                                                                                                                                                                              ...   \n",
       "32377                                [-354.37424, 153.82423, 2.520186, 8.557072, -62.9833, -70.76247, 31.027435, -28.974052, -1.3362603, -6.622672, -28.985481, 6.8635836, -23.302856, 17.592358, 1.9556779, -8.322697, 1.6778979, -5.984693, -9.394501, -18.730194]   \n",
       "32378                           [-541.0925, -20.647453, -19.415312, -3.7550635, -25.011345, 7.143332, -16.555939, -10.724681, 13.894259, 10.9246235, -23.339613, -8.79563, 11.684788, 1.0004408, 9.840512, -4.0137005, 5.4408083, -1.9365463, -10.327684, 1.4280273]   \n",
       "32379                         [-361.39725, 200.15135, -11.198521, -74.57884, -26.557076, -30.454882, -26.454899, -23.900236, -6.9710026, 10.228376, -62.84133, 9.395352, -1.8819872, -2.3180122, 9.137184, -22.453075, 9.633455, -0.8796562, -26.236694, -2.5513773]   \n",
       "32380                      [-560.96643, 85.371414, -12.350075, -33.760818, -45.370388, 11.333093, -5.9454966, -0.63891798, 3.0575819, -33.63752, 20.533573, 1.9418074, 10.326906, 4.8501635, -0.17955418, -8.1675873, -6.8336906, 10.819086, -4.0187063, -1.4526093]   \n",
       "32381                        [-460.5466, 124.15584, -70.547966, -20.204004, -22.291546, -13.947313, -28.85445, -36.783035, 13.090644, -21.71759, -8.811714, -18.16044, -16.802431, 1.4008222, -27.485973, -12.374393, -11.544936, -19.798939, -9.840371, -13.991043]   \n",
       "\n",
       "                                                                                      label  \\\n",
       "0              [0.5575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4425]   \n",
       "1      [0.81916667, 0.18083333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "2              [0.7725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2275]   \n",
       "3                    [0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4]   \n",
       "4      [0.58333333, 0.41666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "...                                                                                     ...   \n",
       "32377                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "32378                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "32379                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "32380                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "32381                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "\n",
       "                                                state_weights  \\\n",
       "0                               {'#b': 0.4425, 'b-n': 0.5575}   \n",
       "1      {'b-n': 0.8191666666666697, 'm-n': 0.1808333333333303}   \n",
       "2                               {'#b': 0.2275, 'b-n': 0.7725}   \n",
       "3                                     {'#b': 0.4, 'b-n': 0.6}   \n",
       "4      {'b-n': 0.5833333333333303, 'm-n': 0.4166666666666697}   \n",
       "...                                                       ...   \n",
       "32377                                             {'#b': 1.0}   \n",
       "32378                                             {'#b': 1.0}   \n",
       "32379                                             {'#b': 1.0}   \n",
       "32380                                             {'#b': 1.0}   \n",
       "32381                                             {'#b': 1.0}   \n",
       "\n",
       "       single_class_label  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "...                   ...  \n",
       "32377                  13  \n",
       "32378                  13  \n",
       "32379                  13  \n",
       "32380                  13  \n",
       "32381                  13  \n",
       "\n",
       "[32382 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def upsample_multiple_minority(df):\n",
    "\n",
    "    # Assuming df_train_pre is your dataframe\n",
    "    # Identify majority and minority classes\n",
    "    majority_classes = [13, 14]\n",
    "    minority_classes = list(range(13))\n",
    "\n",
    "    # Find the size of the smallest majority class\n",
    "    majority_class_size = df_train_pre['single_class_label'].value_counts().nlargest(2).iloc[1]\n",
    "    \n",
    "    # List to hold the upsampled dataframes\n",
    "    list_df = []\n",
    "\n",
    "    # Loop through each minority class and upsample\n",
    "    for class_value in minority_classes:\n",
    "        df_minority_class = df_train_pre[df_train_pre['single_class_label'] == class_value]\n",
    "        df_minority_upsampled = resample(df_minority_class, \n",
    "                                        replace=True,     # sample with replacement\n",
    "                                        n_samples=majority_class_size,    # to match majority class size\n",
    "                                        random_state=123) # reproducible results\n",
    "        list_df.append(df_minority_upsampled)\n",
    "\n",
    "    # Append majority classes without change\n",
    "    df_majority = df_train_pre[df_train_pre['single_class_label'].isin(majority_classes)]\n",
    "    list_df.append(df_majority)\n",
    "\n",
    "    # Concatenate all dataframes\n",
    "    df_upsampled = pd.concat(list_df)\n",
    "    return df_upsampled\n",
    "\n",
    "df_train = upsample_multiple_minority(df_train_pre)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "display(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>single_class_label</th>\n",
       "      <th>13</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8319</td>\n",
       "      <td>1851</td>\n",
       "      <td>1851</td>\n",
       "      <td>1851</td>\n",
       "      <td>1851</td>\n",
       "      <td>1851</td>\n",
       "      <td>1851</td>\n",
       "      <td>1851</td>\n",
       "      <td>1851</td>\n",
       "      <td>1851</td>\n",
       "      <td>1851</td>\n",
       "      <td>1851</td>\n",
       "      <td>1851</td>\n",
       "      <td>1851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8319</td>\n",
       "      <td>204</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>252</td>\n",
       "      <td>239</td>\n",
       "      <td>233</td>\n",
       "      <td>138</td>\n",
       "      <td>146</td>\n",
       "      <td>148</td>\n",
       "      <td>159</td>\n",
       "      <td>166</td>\n",
       "      <td>180</td>\n",
       "      <td>1851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "single_class_label    13    0     1     2     3     4     5     6     7   \\\n",
       "count               8319  1851  1851  1851  1851  1851  1851  1851  1851   \n",
       "count               8319   204   179   180   252   239   233   138   146   \n",
       "\n",
       "single_class_label    8     9     10    11    12  \n",
       "count               1851  1851  1851  1851  1851  \n",
       "count                148   159   166   180  1851  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(pd.DataFrame([df_train['single_class_label'].value_counts(),df_train_pre['single_class_label'].value_counts()]))\n",
    "\n",
    "#Questions:\n",
    "#1- MFCC's that correspond to the same phoneme are closer in the feature space.\n",
    "#   Should we take advantage of this while oversampling? (e.g. taking convex combination of two observations.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('timit/data/TRAIN/DR2/FPJF0/SX146.WAV',\n",
       "  'timit/data/TRAIN/DR2/FPJF0/SX146.PHN',\n",
       "  'timit/data/TRAIN/DR2/FPJF0/SX146.WRD'),\n",
       " ('timit/data/TRAIN/DR3/MDBB1/SX376.WAV',\n",
       "  'timit/data/TRAIN/DR3/MDBB1/SX376.PHN',\n",
       "  'timit/data/TRAIN/DR3/MDBB1/SX376.WRD'),\n",
       " ('timit/data/TRAIN/DR5/MPMB0/SX61.WAV',\n",
       "  'timit/data/TRAIN/DR5/MPMB0/SX61.PHN',\n",
       "  'timit/data/TRAIN/DR5/MPMB0/SX61.WRD'),\n",
       " ('timit/data/TRAIN/DR4/MJLS0/SX376.WAV',\n",
       "  'timit/data/TRAIN/DR4/MJLS0/SX376.PHN',\n",
       "  'timit/data/TRAIN/DR4/MJLS0/SX376.WRD'),\n",
       " ('timit/data/TRAIN/DR3/MTJM0/SX146.WAV',\n",
       "  'timit/data/TRAIN/DR3/MTJM0/SX146.PHN',\n",
       "  'timit/data/TRAIN/DR3/MTJM0/SX146.WRD'),\n",
       " ('timit/data/TRAIN/DR7/MBBR0/SX425.WAV',\n",
       "  'timit/data/TRAIN/DR7/MBBR0/SX425.PHN',\n",
       "  'timit/data/TRAIN/DR7/MBBR0/SX425.WRD'),\n",
       " ('timit/data/TRAIN/DR5/FCDR1/SX376.WAV',\n",
       "  'timit/data/TRAIN/DR5/FCDR1/SX376.PHN',\n",
       "  'timit/data/TRAIN/DR5/FCDR1/SX376.WRD'),\n",
       " ('timit/data/TRAIN/DR4/MLJC0/SI1855.WAV',\n",
       "  'timit/data/TRAIN/DR4/MLJC0/SI1855.PHN',\n",
       "  'timit/data/TRAIN/DR4/MLJC0/SI1855.WRD'),\n",
       " ('timit/data/TRAIN/DR5/MTAT0/SX210.WAV',\n",
       "  'timit/data/TRAIN/DR5/MTAT0/SX210.PHN',\n",
       "  'timit/data/TRAIN/DR5/MTAT0/SX210.WRD'),\n",
       " ('timit/data/TRAIN/DR1/FDAW0/SX146.WAV',\n",
       "  'timit/data/TRAIN/DR1/FDAW0/SX146.PHN',\n",
       "  'timit/data/TRAIN/DR1/FDAW0/SX146.WRD'),\n",
       " ('timit/data/TEST/DR1/MDAB0/SI1039.WAV',\n",
       "  'timit/data/TEST/DR1/MDAB0/SI1039.PHN',\n",
       "  'timit/data/TEST/DR1/MDAB0/SI1039.WRD'),\n",
       " ('timit/data/TRAIN/DR7/MREM0/SX61.WAV',\n",
       "  'timit/data/TRAIN/DR7/MREM0/SX61.PHN',\n",
       "  'timit/data/TRAIN/DR7/MREM0/SX61.WRD'),\n",
       " ('timit/data/TRAIN/DR2/FHLM0/SX210.WAV',\n",
       "  'timit/data/TRAIN/DR2/FHLM0/SX210.PHN',\n",
       "  'timit/data/TRAIN/DR2/FHLM0/SX210.WRD'),\n",
       " ('timit/data/TRAIN/DR4/MKAM0/SX146.WAV',\n",
       "  'timit/data/TRAIN/DR4/MKAM0/SX146.PHN',\n",
       "  'timit/data/TRAIN/DR4/MKAM0/SX146.WRD'),\n",
       " ('timit/data/TRAIN/DR4/MARW0/SX376.WAV',\n",
       "  'timit/data/TRAIN/DR4/MARW0/SX376.PHN',\n",
       "  'timit/data/TRAIN/DR4/MARW0/SX376.WRD'),\n",
       " ('timit/data/TRAIN/DR2/MRMS0/SX210.WAV',\n",
       "  'timit/data/TRAIN/DR2/MRMS0/SX210.PHN',\n",
       "  'timit/data/TRAIN/DR2/MRMS0/SX210.WRD'),\n",
       " ('timit/data/TRAIN/DR5/MCLM0/SX376.WAV',\n",
       "  'timit/data/TRAIN/DR5/MCLM0/SX376.PHN',\n",
       "  'timit/data/TRAIN/DR5/MCLM0/SX376.WRD'),\n",
       " ('timit/data/TRAIN/DR4/MDMA0/SX440.WAV',\n",
       "  'timit/data/TRAIN/DR4/MDMA0/SX440.PHN',\n",
       "  'timit/data/TRAIN/DR4/MDMA0/SX440.WRD'),\n",
       " ('timit/data/TRAIN/DR4/MDCD0/SX425.WAV',\n",
       "  'timit/data/TRAIN/DR4/MDCD0/SX425.PHN',\n",
       "  'timit/data/TRAIN/DR4/MDCD0/SX425.WRD'),\n",
       " ('timit/data/TRAIN/DR8/MRDM0/SX425.WAV',\n",
       "  'timit/data/TRAIN/DR8/MRDM0/SX425.PHN',\n",
       "  'timit/data/TRAIN/DR8/MRDM0/SX425.WRD'),\n",
       " ('timit/data/TRAIN/DR5/MJRG0/SX376.WAV',\n",
       "  'timit/data/TRAIN/DR5/MJRG0/SX376.PHN',\n",
       "  'timit/data/TRAIN/DR5/MJRG0/SX376.WRD'),\n",
       " ('timit/data/TRAIN/DR8/FBCG1/SI1612.WAV',\n",
       "  'timit/data/TRAIN/DR8/FBCG1/SI1612.PHN',\n",
       "  'timit/data/TRAIN/DR8/FBCG1/SI1612.WRD'),\n",
       " ('timit/data/TRAIN/DR3/MDTB0/SX210.WAV',\n",
       "  'timit/data/TRAIN/DR3/MDTB0/SX210.PHN',\n",
       "  'timit/data/TRAIN/DR3/MDTB0/SX210.WRD'),\n",
       " ('timit/data/TRAIN/DR1/MTPF0/SX425.WAV',\n",
       "  'timit/data/TRAIN/DR1/MTPF0/SX425.PHN',\n",
       "  'timit/data/TRAIN/DR1/MTPF0/SX425.WRD'),\n",
       " ('timit/data/TRAIN/DR7/MDLC1/SI2065.WAV',\n",
       "  'timit/data/TRAIN/DR7/MDLC1/SI2065.PHN',\n",
       "  'timit/data/TRAIN/DR7/MDLC1/SI2065.WRD'),\n",
       " ('timit/data/TRAIN/DR7/FKDE0/SX61.WAV',\n",
       "  'timit/data/TRAIN/DR7/FKDE0/SX61.PHN',\n",
       "  'timit/data/TRAIN/DR7/FKDE0/SX61.WRD'),\n",
       " ('timit/data/TRAIN/DR3/MDWM0/SX376.WAV',\n",
       "  'timit/data/TRAIN/DR3/MDWM0/SX376.PHN',\n",
       "  'timit/data/TRAIN/DR3/MDWM0/SX376.WRD'),\n",
       " ('timit/data/TRAIN/DR2/FMMH0/SI907.WAV',\n",
       "  'timit/data/TRAIN/DR2/FMMH0/SI907.PHN',\n",
       "  'timit/data/TRAIN/DR2/FMMH0/SI907.WRD'),\n",
       " ('timit/data/TRAIN/DR3/FJLR0/SX61.WAV',\n",
       "  'timit/data/TRAIN/DR3/FJLR0/SX61.PHN',\n",
       "  'timit/data/TRAIN/DR3/FJLR0/SX61.WRD')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load('processed_data/train_test_dataset_never.joblib')['test'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset into a format that torch can read.\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, train=True):\n",
    "        # Convert the DataFrame to tensors or appropriate formats initially\n",
    "        self.mfcc = torch.tensor(np.vstack(dataframe['mfcc'].to_list()), dtype=torch.float32)\n",
    "        self.label = torch.tensor(np.vstack(dataframe['label'].to_list()), dtype=torch.float32)\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfcc = self.mfcc[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            mfcc = self.transform(mfcc)\n",
    "\n",
    "        return mfcc, label\n",
    "\n",
    "# Create an instance of your dataset with your DataFrame\n",
    "dataset_train = CustomDataset(df_train, train=True)  # Assuming df is your pandas DataFrame\n",
    "dataset_val = CustomDataset(df_val, train=True)\n",
    "dataset_test = CustomDataset(df_test,train=False)\n",
    "\n",
    "\n",
    "# Create the DataLoader to handle batching\n",
    "loader_train = DataLoader(dataset_train, batch_size=minibatch_size,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(len(df_train))))\n",
    "\n",
    "loader_val = DataLoader(dataset_val, batch_size=1,\n",
    "                        sampler=sampler.SequentialSampler(range(len(df_val))))\n",
    "\n",
    "loader_test = DataLoader(dataset_test, batch_size=1,\n",
    "                        sampler=sampler.SequentialSampler(range(len(df_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1\n",
      "MFCC shape: torch.Size([64, 20])\n",
      "Label shape: tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.1650, 0.8350, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3000, 0.5550, 0.1450, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6333, 0.1667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.2000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.4183, 0.5817, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.2333, 0.7667, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.9975, 0.0025],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.4808, 0.5192, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.5083, 0.4917, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.5000, 0.0000, 0.5000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.4050, 0.5950, 0.0000, 0.0000],\n",
      "        [0.5058, 0.4942, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6900, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.3100],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.8250, 0.1750],\n",
      "        [0.0400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9600,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2042, 0.7958, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.1025, 0.8975, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6433, 0.3567, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.7000, 0.0000, 0.0000, 0.0000, 0.3000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.5867, 0.4133, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.3708, 0.6292, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4175, 0.4175, 0.1650,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.7000, 0.0000, 0.3000],\n",
      "        [0.6000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.4000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5633, 0.4367, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4492, 0.5508, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.4175, 0.5825, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.5108, 0.1392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.3500],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3725, 0.6275, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2725,\n",
      "         0.7275, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3808, 0.6192, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6000,\n",
      "         0.4000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7300, 0.1700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.5000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1625, 0.8375, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4300, 0.5700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1592, 0.3583,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.4825],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0958, 0.7642,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1400],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.2092, 0.7908, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5117, 0.0758, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.4125, 0.0000],\n",
      "        [0.6475, 0.0000, 0.0000, 0.0000, 0.0000, 0.3525, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.5667, 0.4333, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4000, 0.6000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.4517, 0.5483, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.3708, 0.6292, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.5000]])\n",
      "Batch: 2\n",
      "MFCC shape: torch.Size([64, 20])\n",
      "Label shape: tensor([[0.3300, 0.5300, 0.1400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4000, 0.6000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.4783, 0.5217, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.4417, 0.5583, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4367, 0.5633, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3425, 0.6575, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.8092, 0.1908, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1667, 0.8333, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6425, 0.3575,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.7083, 0.2917, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4275, 0.5725, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.3000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.3158, 0.6842, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.4117, 0.5883, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3317, 0.6683, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.5733, 0.4267, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1875, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.8125],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.9500, 0.0500],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.6667, 0.3333, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.5333, 0.4667, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2433, 0.7567, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4000, 0.6000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0325, 0.9400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0275, 0.0000],\n",
      "        [0.8000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7000, 0.3000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2275, 0.7725, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2425, 0.7575, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1000, 0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2350, 0.7650, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5625,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.4375],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.6908, 0.3092, 0.0000, 0.0000],\n",
      "        [0.2492, 0.3492, 0.3492, 0.0525, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.7350, 0.2650, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6625, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.3375],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.9667, 0.0333, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.2000, 0.8000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.3025, 0.6975, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "Batch: 3\n",
      "MFCC shape: torch.Size([64, 20])\n",
      "Label shape: tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.5000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.2550, 0.7450, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4567, 0.5433, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.3000, 0.7000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8433, 0.1567, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0333, 0.9667, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8667, 0.1333, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2492, 0.7508, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5575, 0.0000, 0.0000, 0.0000, 0.0000, 0.4425, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0575, 0.7833, 0.1592, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.1708, 0.8292, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4850, 0.5150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2417, 0.7583, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5125,\n",
      "         0.4875, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6500, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.3500],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1350, 0.8650, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4950,\n",
      "         0.5050, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.6425, 0.0350, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.3225],\n",
      "        [0.0000, 0.1083, 0.7917, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.6475, 0.3525, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2667, 0.7333, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.5250, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.4750, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.8033, 0.1967, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.5600],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.3925, 0.6075, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000, 0.2000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4408, 0.5592, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.7000, 0.0000, 0.3000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.5000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.6092, 0.3908, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2408, 0.7592, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6633, 0.3367, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.5733, 0.4267, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.7333, 0.2667, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2208, 0.7792, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1742, 0.7308,\n",
      "         0.0950, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4550, 0.5450, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4333, 0.5667, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3925, 0.0000, 0.0000, 0.0000, 0.0517, 0.5558, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "Batch: 4\n",
      "MFCC shape: torch.Size([64, 20])\n",
      "Label shape: tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.8933, 0.1067, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.8000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1142, 0.5017, 0.3842,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.1167, 0.8833, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.6092, 0.3908, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3475,\n",
      "         0.4058, 0.2467, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4425,\n",
      "         0.5575, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4175, 0.4175, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1375],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2433, 0.7567, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.7000, 0.3000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9200,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0800],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9025, 0.0975, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.5167, 0.4833, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4000, 0.6000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5592, 0.4408, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0792, 0.9208, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7067, 0.2508, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0425],\n",
      "        [0.1275, 0.8725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000,\n",
      "         0.5000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.5333, 0.4667, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4192, 0.5808, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.1000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0992, 0.9008,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4333, 0.5667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4192, 0.5808, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7000, 0.3000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.1000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.7000, 0.0000, 0.3000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.4917, 0.5083, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3583, 0.6417, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4800,\n",
      "         0.5200, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.4517, 0.5483, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1000, 0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.5833, 0.4167, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2633, 0.7367, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9600,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.9000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2225, 0.7775, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0292, 0.9708,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.8092, 0.1908, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.7667, 0.2333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(loader_train):\n",
    "    print(f'Batch: {i+1}')\n",
    "    print(f'MFCC shape: {x.shape}')\n",
    "    print(f'Label shape: {y}') \n",
    "    if i >2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 14])\n"
     ]
    }
   ],
   "source": [
    "class DNN_FC(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        # assign layer objects to class attributes\n",
    "        # We may write a loop if we use the same activation function for all layers.\n",
    "        self.fc1 = nn.Linear(input_size, input_size)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(input_size, input_size)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight) \n",
    "        self.fc3 = nn.Linear(input_size, input_size)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight)\n",
    "        self.fc4 = nn.Linear(input_size, input_size)\n",
    "        nn.init.kaiming_normal_(self.fc4.weight)\n",
    "        self.fc5 = nn.Linear(input_size, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc5.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_temp = DNN_utils.flatten(x) # Flatten the batch to convert dimensions from (N,C,1) to (N,-1)\n",
    "        x_temp = F.relu(self.fc1(x_temp))\n",
    "        x_temp = F.relu(self.fc2(x_temp))\n",
    "        x_temp = F.relu(self.fc3(x_temp))\n",
    "        x_temp = F.relu(self.fc4(x_temp))\n",
    "        scores = self.fc5(x_temp)\n",
    "        return scores\n",
    "\n",
    "\n",
    "def test_DNN_FC():\n",
    "    input_size = len(df_train.iloc[0]['mfcc'])  # Feature dimension for mfcc\n",
    "    num_classes = len(df_train.iloc[0]['label']) # Number of phoneme classes \n",
    "    x = torch.zeros((minibatch_size, input_size), dtype=dtype)  # minibatch size 64, feature dimension 20\n",
    "    model = DNN_FC(input_size, num_classes)\n",
    "    scores = model(x)\n",
    "    print(scores.size())  # you should see [minibatch_size, num_classes]\n",
    "test_DNN_FC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, epochs=1, print_every=50):\n",
    "\n",
    "    \"\"\"\n",
    "    Train the model using the PyTorch Module API.\n",
    "\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    - scheduler: Learning rate scheduler \n",
    "\n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    val_loss_lst = []\n",
    "    train_loss_lst = []\n",
    "    accuracy_val_max = 0\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            y = DNN_utils.flatten(y) # Flatten y to convert the dimension from (Nx1) to (N,)\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU \n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            scores = model(x)\n",
    "\n",
    "            criterion = nn.KLDivLoss(reduction = \"batchmean\")\n",
    "            loss = criterion(F.log_softmax(scores), y) \n",
    "\n",
    "            # Compare the output vector with the label vector using BCEwithLogitsLoss.\n",
    "            # criterion = nn.CrossEntropyLoss()\n",
    "            # loss = criterion(scores, y)  # nn.KLDivLoss expects the NN output to be in the log-softmax scale. \n",
    "            \n",
    "            # criterion = nn.BCEWithLogitsLoss() \n",
    "            # loss = criterion(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "            \n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % print_every == 0:\n",
    "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
    "                print()\n",
    "                accuracy_val = DNN_utils.check_accuracy(loader_val, model)\n",
    "                val_loss = DNN_utils.check_loss(loader_val, model) \n",
    "                if accuracy_val > accuracy_val_max:\n",
    "                    accuracy_val_max = accuracy_val \n",
    "                train_loss_lst.append(loss.item())\n",
    "                val_loss_lst.append(val_loss.item()) \n",
    "        \n",
    "        # Update the learning rate at every epoch.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Plot the accuracy values\n",
    "    plt.plot(val_loss_lst, label='Validation Loss')\n",
    "    plt.plot(train_loss_lst, label='Training Loss')\n",
    "\n",
    "    # Add labels and title to the plot\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    return train_loss_lst, val_loss_lst\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f4/lgpjzfp563j334v5qtjdxx100000gn/T/ipykernel_4712/4138625467.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = criterion(F.log_softmax(scores), y)\n",
      "/Users/eminozyoruk/Library/CloudStorage/GoogleDrive-emin.ozyoruk@chicagobooth.edu/My Drive/Chicago/Academic/Booth 4.3/Probabilistic Graphical Models/Project/Codes/keyword-spotting/DNN_utils.py:60: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = criterion(F.log_softmax(scores), y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0, loss = 386.9558\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 744 / 3099 correct (24.01)\n",
      "Epoch 0, Iteration 50, loss = 1.9839\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1815 / 3099 correct (58.57)\n",
      "Epoch 0, Iteration 100, loss = 1.8248\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1922 / 3099 correct (62.02)\n",
      "Epoch 0, Iteration 150, loss = 1.5522\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1910 / 3099 correct (61.63)\n",
      "Epoch 0, Iteration 200, loss = 1.6904\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1787 / 3099 correct (57.66)\n",
      "Epoch 0, Iteration 250, loss = 1.5080\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1781 / 3099 correct (57.47)\n",
      "Epoch 0, Iteration 300, loss = 1.5826\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1814 / 3099 correct (58.54)\n",
      "Epoch 0, Iteration 350, loss = 1.5317\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1767 / 3099 correct (57.02)\n",
      "Epoch 0, Iteration 400, loss = 1.3311\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1813 / 3099 correct (58.50)\n",
      "Epoch 0, Iteration 450, loss = 1.5011\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1756 / 3099 correct (56.66)\n",
      "Epoch 0, Iteration 500, loss = 1.6492\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1793 / 3099 correct (57.86)\n",
      "Epoch 1, Iteration 0, loss = 1.4152\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1799 / 3099 correct (58.05)\n",
      "Epoch 1, Iteration 50, loss = 1.4958\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 2030 / 3099 correct (65.51)\n",
      "Epoch 1, Iteration 100, loss = 1.3983\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1824 / 3099 correct (58.86)\n",
      "Epoch 1, Iteration 150, loss = 1.2738\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1901 / 3099 correct (61.34)\n",
      "Epoch 1, Iteration 200, loss = 1.3147\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1833 / 3099 correct (59.15)\n",
      "Epoch 1, Iteration 250, loss = 1.2726\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1807 / 3099 correct (58.31)\n",
      "Epoch 1, Iteration 300, loss = 1.3311\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1861 / 3099 correct (60.05)\n",
      "Epoch 1, Iteration 350, loss = 1.3083\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1848 / 3099 correct (59.63)\n",
      "Epoch 1, Iteration 400, loss = 1.3611\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 2019 / 3099 correct (65.15)\n",
      "Epoch 1, Iteration 450, loss = 1.3593\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1940 / 3099 correct (62.60)\n",
      "Epoch 1, Iteration 500, loss = 1.2672\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1857 / 3099 correct (59.92)\n",
      "Epoch 2, Iteration 0, loss = 1.5475\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1876 / 3099 correct (60.54)\n",
      "Epoch 2, Iteration 50, loss = 1.4581\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1850 / 3099 correct (59.70)\n",
      "Epoch 2, Iteration 100, loss = 1.4795\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1945 / 3099 correct (62.76)\n",
      "Epoch 2, Iteration 150, loss = 1.4229\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1814 / 3099 correct (58.54)\n",
      "Epoch 2, Iteration 200, loss = 1.2467\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1947 / 3099 correct (62.83)\n",
      "Epoch 2, Iteration 250, loss = 1.3004\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1726 / 3099 correct (55.70)\n",
      "Epoch 2, Iteration 300, loss = 1.2867\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1913 / 3099 correct (61.73)\n",
      "Epoch 2, Iteration 350, loss = 1.3022\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1892 / 3099 correct (61.05)\n",
      "Epoch 2, Iteration 400, loss = 1.1785\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1739 / 3099 correct (56.11)\n",
      "Epoch 2, Iteration 450, loss = 1.3971\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1942 / 3099 correct (62.67)\n",
      "Epoch 2, Iteration 500, loss = 1.4218\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1944 / 3099 correct (62.73)\n",
      "Epoch 3, Iteration 0, loss = 1.2084\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1879 / 3099 correct (60.63)\n",
      "Epoch 3, Iteration 50, loss = 1.3989\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1920 / 3099 correct (61.96)\n",
      "Epoch 3, Iteration 100, loss = 1.2194\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1777 / 3099 correct (57.34)\n",
      "Epoch 3, Iteration 150, loss = 1.2894\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1781 / 3099 correct (57.47)\n",
      "Epoch 3, Iteration 200, loss = 1.3610\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1713 / 3099 correct (55.28)\n",
      "Epoch 3, Iteration 250, loss = 1.1765\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1891 / 3099 correct (61.02)\n",
      "Epoch 3, Iteration 300, loss = 1.2168\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1900 / 3099 correct (61.31)\n",
      "Epoch 3, Iteration 350, loss = 1.3534\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1817 / 3099 correct (58.63)\n",
      "Epoch 3, Iteration 400, loss = 1.2600\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1938 / 3099 correct (62.54)\n",
      "Epoch 3, Iteration 450, loss = 1.3342\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1763 / 3099 correct (56.89)\n",
      "Epoch 3, Iteration 500, loss = 1.2664\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1814 / 3099 correct (58.54)\n",
      "Epoch 4, Iteration 0, loss = 1.1823\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1863 / 3099 correct (60.12)\n",
      "Epoch 4, Iteration 50, loss = 1.3448\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1877 / 3099 correct (60.57)\n",
      "Epoch 4, Iteration 100, loss = 1.2157\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1878 / 3099 correct (60.60)\n",
      "Epoch 4, Iteration 150, loss = 1.1385\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1826 / 3099 correct (58.92)\n",
      "Epoch 4, Iteration 200, loss = 1.3962\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1741 / 3099 correct (56.18)\n",
      "Epoch 4, Iteration 250, loss = 1.3135\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 2067 / 3099 correct (66.70)\n",
      "Epoch 4, Iteration 300, loss = 1.2700\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1790 / 3099 correct (57.76)\n",
      "Epoch 4, Iteration 350, loss = 1.4733\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1574 / 3099 correct (50.79)\n",
      "Epoch 4, Iteration 400, loss = 1.1804\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1825 / 3099 correct (58.89)\n",
      "Epoch 4, Iteration 450, loss = 1.0933\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1833 / 3099 correct (59.15)\n",
      "Epoch 4, Iteration 500, loss = 1.4793\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1523 / 3099 correct (49.14)\n",
      "Epoch 5, Iteration 0, loss = 1.3376\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1581 / 3099 correct (51.02)\n",
      "Epoch 5, Iteration 50, loss = 1.3739\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1871 / 3099 correct (60.37)\n",
      "Epoch 5, Iteration 100, loss = 1.0588\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1836 / 3099 correct (59.24)\n",
      "Epoch 5, Iteration 150, loss = 1.2369\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1891 / 3099 correct (61.02)\n",
      "Epoch 5, Iteration 200, loss = 1.1952\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1991 / 3099 correct (64.25)\n",
      "Epoch 5, Iteration 250, loss = 1.1195\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1814 / 3099 correct (58.54)\n",
      "Epoch 5, Iteration 300, loss = 1.3022\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1803 / 3099 correct (58.18)\n",
      "Epoch 5, Iteration 350, loss = 1.2786\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1883 / 3099 correct (60.76)\n",
      "Epoch 5, Iteration 400, loss = 1.1527\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1941 / 3099 correct (62.63)\n",
      "Epoch 5, Iteration 450, loss = 1.2251\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1763 / 3099 correct (56.89)\n",
      "Epoch 5, Iteration 500, loss = 1.2588\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1718 / 3099 correct (55.44)\n",
      "Epoch 6, Iteration 0, loss = 1.2590\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1839 / 3099 correct (59.34)\n",
      "Epoch 6, Iteration 50, loss = 1.2819\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1916 / 3099 correct (61.83)\n",
      "Epoch 6, Iteration 100, loss = 1.2105\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1808 / 3099 correct (58.34)\n",
      "Epoch 6, Iteration 150, loss = 1.3888\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1753 / 3099 correct (56.57)\n",
      "Epoch 6, Iteration 200, loss = 1.0867\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1738 / 3099 correct (56.08)\n",
      "Epoch 6, Iteration 250, loss = 1.1358\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1749 / 3099 correct (56.44)\n",
      "Epoch 6, Iteration 300, loss = 1.1086\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1761 / 3099 correct (56.82)\n",
      "Epoch 6, Iteration 350, loss = 1.1873\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1888 / 3099 correct (60.92)\n",
      "Epoch 6, Iteration 400, loss = 0.9458\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1859 / 3099 correct (59.99)\n",
      "Epoch 6, Iteration 450, loss = 1.1753\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1815 / 3099 correct (58.57)\n",
      "Epoch 6, Iteration 500, loss = 1.1093\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1826 / 3099 correct (58.92)\n",
      "Epoch 7, Iteration 0, loss = 1.4108\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1792 / 3099 correct (57.83)\n",
      "Epoch 7, Iteration 50, loss = 1.1383\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1739 / 3099 correct (56.11)\n",
      "Epoch 7, Iteration 100, loss = 1.0543\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1815 / 3099 correct (58.57)\n",
      "Epoch 7, Iteration 150, loss = 1.3107\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1802 / 3099 correct (58.15)\n",
      "Epoch 7, Iteration 200, loss = 1.1679\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1864 / 3099 correct (60.15)\n",
      "Epoch 7, Iteration 250, loss = 1.1002\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1840 / 3099 correct (59.37)\n",
      "Epoch 7, Iteration 300, loss = 1.1931\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1743 / 3099 correct (56.24)\n",
      "Epoch 7, Iteration 350, loss = 1.2108\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1653 / 3099 correct (53.34)\n",
      "Epoch 7, Iteration 400, loss = 1.1955\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1867 / 3099 correct (60.25)\n",
      "Epoch 7, Iteration 450, loss = 1.1997\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1806 / 3099 correct (58.28)\n",
      "Epoch 7, Iteration 500, loss = 1.1838\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1598 / 3099 correct (51.57)\n",
      "Epoch 8, Iteration 0, loss = 1.0612\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1710 / 3099 correct (55.18)\n",
      "Epoch 8, Iteration 50, loss = 0.9834\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1861 / 3099 correct (60.05)\n",
      "Epoch 8, Iteration 100, loss = 1.1754\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1864 / 3099 correct (60.15)\n",
      "Epoch 8, Iteration 150, loss = 0.9583\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1792 / 3099 correct (57.83)\n",
      "Epoch 8, Iteration 200, loss = 1.0977\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1745 / 3099 correct (56.31)\n",
      "Epoch 8, Iteration 250, loss = 1.1584\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1753 / 3099 correct (56.57)\n",
      "Epoch 8, Iteration 300, loss = 1.0776\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1824 / 3099 correct (58.86)\n",
      "Epoch 8, Iteration 350, loss = 1.1488\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1794 / 3099 correct (57.89)\n",
      "Epoch 8, Iteration 400, loss = 1.1538\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1828 / 3099 correct (58.99)\n",
      "Epoch 8, Iteration 450, loss = 1.1767\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1941 / 3099 correct (62.63)\n",
      "Epoch 8, Iteration 500, loss = 1.0366\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1850 / 3099 correct (59.70)\n",
      "Epoch 9, Iteration 0, loss = 1.1854\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1806 / 3099 correct (58.28)\n",
      "Epoch 9, Iteration 50, loss = 1.0762\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1719 / 3099 correct (55.47)\n",
      "Epoch 9, Iteration 100, loss = 1.2657\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1848 / 3099 correct (59.63)\n",
      "Epoch 9, Iteration 150, loss = 1.0411\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1804 / 3099 correct (58.21)\n",
      "Epoch 9, Iteration 200, loss = 1.0396\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1846 / 3099 correct (59.57)\n",
      "Epoch 9, Iteration 250, loss = 1.1499\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1838 / 3099 correct (59.31)\n",
      "Epoch 9, Iteration 300, loss = 1.0288\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1777 / 3099 correct (57.34)\n",
      "Epoch 9, Iteration 350, loss = 1.1805\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1773 / 3099 correct (57.21)\n",
      "Epoch 9, Iteration 400, loss = 1.0720\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1873 / 3099 correct (60.44)\n",
      "Epoch 9, Iteration 450, loss = 1.1764\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1899 / 3099 correct (61.28)\n",
      "Epoch 9, Iteration 500, loss = 1.0666\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 1692 / 3099 correct (54.60)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "input_size = len(df_train.iloc[0]['mfcc'])\n",
    "num_classes = len(df_train.iloc[0]['label'])\n",
    "learning_rate = 1e-2 \n",
    "model = DNN_FC(input_size, num_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate) \n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "train_loss_lst, val_loss_lst = train(model, optimizer, scheduler, epochs = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[386.955810546875, 1.9838876724243164, 1.8248276710510254, 1.5522128343582153, 1.6903941631317139, 1.5080244541168213, 1.5826208591461182, 1.5316863059997559, 1.331052303314209, 1.5011088848114014, 1.6492044925689697, 1.4152365922927856, 1.4957512617111206, 1.3982996940612793, 1.2737953662872314, 1.3146942853927612, 1.272568702697754, 1.331054925918579, 1.3083174228668213, 1.3610938787460327, 1.3593206405639648, 1.2672340869903564, 1.5475497245788574, 1.4581120014190674, 1.4794862270355225, 1.422924280166626, 1.2466623783111572, 1.3004350662231445, 1.2867226600646973, 1.302245855331421, 1.178504228591919, 1.3970636129379272, 1.4217946529388428, 1.2084027528762817, 1.3988689184188843, 1.2193708419799805, 1.2893835306167603, 1.3610165119171143, 1.176540732383728, 1.2167742252349854, 1.3534369468688965, 1.2599530220031738, 1.334246039390564, 1.2664339542388916, 1.182286262512207, 1.3447741270065308, 1.2156765460968018, 1.138542652130127, 1.3961601257324219, 1.3135173320770264, 1.270049810409546, 1.4733238220214844, 1.1803641319274902, 1.093311071395874, 1.479301929473877, 1.337592363357544, 1.3739278316497803, 1.0587786436080933, 1.236850380897522, 1.1951534748077393, 1.1194660663604736, 1.3022208213806152, 1.2785694599151611, 1.1526590585708618, 1.2250828742980957, 1.2588462829589844, 1.2589634656906128, 1.2818799018859863, 1.2104570865631104, 1.3887914419174194, 1.0867340564727783, 1.135758876800537, 1.1086422204971313, 1.1873353719711304, 0.9458025097846985, 1.175316333770752, 1.109311580657959, 1.4108108282089233, 1.1382917165756226, 1.0543463230133057, 1.310747742652893, 1.1679267883300781, 1.1001660823822021, 1.1931073665618896, 1.210793375968933, 1.1955171823501587, 1.1996724605560303, 1.1838462352752686, 1.0612105131149292, 0.9834432005882263, 1.175384759902954, 0.9583003520965576, 1.0976812839508057, 1.1583821773529053, 1.0776050090789795, 1.1488348245620728, 1.1537846326828003, 1.176693320274353, 1.0366181135177612, 1.1853622198104858, 1.076151967048645, 1.265669584274292, 1.041110634803772, 1.0395636558532715, 1.1499254703521729, 1.0288125276565552, 1.1804988384246826, 1.0719797611236572, 1.1763781309127808, 1.0666358470916748]\n",
      "[366778.15625, 4684.99169921875, 4633.4609375, 4161.5380859375, 4254.48828125, 4141.14208984375, 4226.875, 3984.38818359375, 3830.935302734375, 3847.302001953125, 4121.88623046875, 3938.708740234375, 3529.943603515625, 3784.690185546875, 3832.166015625, 3610.068359375, 3794.740966796875, 3863.13427734375, 3689.36083984375, 3599.815185546875, 3751.182861328125, 3695.121826171875, 3899.277099609375, 3843.539794921875, 3646.796142578125, 3816.675048828125, 3658.802001953125, 3962.40380859375, 3710.203369140625, 3559.5244140625, 3849.676513671875, 3678.479736328125, 3654.40966796875, 3637.08984375, 3574.41650390625, 3783.702880859375, 3786.892333984375, 3991.04345703125, 3579.426025390625, 3525.427734375, 3583.5810546875, 3443.78955078125, 3729.81103515625, 3672.0966796875, 3567.4296875, 3679.05712890625, 3383.058837890625, 3555.842041015625, 3705.435546875, 3172.82666015625, 3761.808349609375, 4076.046142578125, 3536.233642578125, 3398.969482421875, 4137.6474609375, 3995.887451171875, 3461.507568359375, 3428.0771484375, 3354.245361328125, 3172.03271484375, 3557.4052734375, 3450.4345703125, 3298.7236328125, 3223.959716796875, 3593.19677734375, 3538.22802734375, 3373.90283203125, 3255.354248046875, 3549.27685546875, 3567.28369140625, 3571.343994140625, 3568.066162109375, 3508.266357421875, 3279.484130859375, 3416.152587890625, 3350.485107421875, 3304.649658203125, 3346.36767578125, 3424.825439453125, 3383.920654296875, 3320.461181640625, 3257.037841796875, 3338.23876953125, 3506.296875, 3436.031982421875, 3284.466064453125, 3281.86181640625, 3754.95849609375, 3533.776123046875, 3202.449951171875, 3190.075439453125, 3304.21435546875, 3410.609375, 3335.186767578125, 3263.000244140625, 3328.222412109375, 3240.32470703125, 3055.905029296875, 3174.26123046875, 3262.997314453125, 3474.25732421875, 3182.236572265625, 3280.862060546875, 3232.88720703125, 3113.314697265625, 3374.310791015625, 3350.25439453125, 3145.917724609375, 3053.35986328125, 3358.609619140625]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x308d06b50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_loss_lst)\n",
    "print(val_loss_lst) \n",
    "\n",
    "# Plot the accuracy values\n",
    "plt.plot(val_loss_lst[2:], label='Validation Loss')\n",
    "plt.plot(train_loss_lst[2:], label='Training Loss')\n",
    "\n",
    "# Add labels and title to the plot\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 1733 / 3099 correct (55.92)\n",
      "Checking accuracy on test set\n",
      "Got 9246 / 17249 correct (53.60)\n",
      "Checking accuracy on validation set\n",
      "Got 13590 / 32382 correct (41.97)\n",
      "Checking accuracy on validation set\n",
      "Got 13590 / 32382 correct (41.97)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4196775986659255"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN_utils.check_accuracy(loader_val, model)\n",
    "DNN_utils.check_accuracy(loader_test, model) \n",
    "DNN_utils.check_accuracy(loader_train, model) \n",
    "\n",
    "loader_train_fortest = DataLoader(dataset_train, batch_size=1,\n",
    "                                  sampler = sampler.SequentialSampler(range(len(df_train))))\n",
    "DNN_utils.check_accuracy(loader_train_fortest, model) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model = DNN_FC(input_size, num_classes) \n",
    "input_size = len(df_train.iloc[0]['mfcc'])\n",
    "num_classes = len(df_train.iloc[0]['label'])\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"model_parameters.pth\"\n",
    "\n",
    "# Load the model parameters\n",
    "saved_model.load_state_dict(torch.load(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 2310 / 3099 correct (74.54)\n",
      "Checking accuracy on test set\n",
      "Got 12813 / 17249 correct (74.28)\n",
      "Checking accuracy on validation set\n",
      "Got 9280 / 32382 correct (28.66)\n",
      "Checking accuracy on validation set\n",
      "Got 9280 / 32382 correct (28.66)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28657896362176516"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN_utils.check_accuracy(loader_val, saved_model)\n",
    "DNN_utils.check_accuracy(loader_test, saved_model) \n",
    "DNN_utils.check_accuracy(loader_train, saved_model) \n",
    "\n",
    "loader_train_fortest = DataLoader(dataset_train, batch_size=1,\n",
    "                                  sampler = sampler.SequentialSampler(range(len(df_train))))\n",
    "DNN_utils.check_accuracy(loader_train_fortest, saved_model) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_probabilities(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Getting estimated probabilities on validation set')\n",
    "    else:\n",
    "        print('Getting estimated probabilities on test set') \n",
    "    model.eval()  # set model to evaluation mode\n",
    "    probabilities_dict = {} \n",
    "    batch_size = loader.batch_size\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, y) in enumerate(loader):\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=dtype) \n",
    "            scores = model(x) \n",
    "            probabilities = torch.softmax(scores, dim=1) \n",
    "            \n",
    "            # Save the probabilities with the corresponding row index\n",
    "            for i in range(len(probabilities)):\n",
    "                probabilities_dict[idx * batch_size + i] = probabilities[i].numpy()\n",
    "    \n",
    "    return probabilities_dict\n",
    "\n",
    "\n",
    "def find_emission(loader, model, scale = False):\n",
    "    '''\n",
    "    Find emission probabilities for a given data loader and model.\n",
    "    Consider changing this function if it takes too long. Currently: O(n) \n",
    "    Args:\n",
    "        loader: torch Data loader\n",
    "        model: torch DNN model\n",
    "        scale: Boolean: Set true to scale the output probability of DNN.\n",
    "    Returns:\n",
    "        emission_df: Dataframe for emission probabilities.\n",
    "    '''\n",
    "    # Get the inferred probabilities for each class (12 states, background and silence)\n",
    "    probabilities_dict = infer_probabilities(loader, model) \n",
    "    emission = probabilities_dict\n",
    "    # Get the prior vector and the transition probabilities. We don't need the transition probabilities.\n",
    "    prior_vector, _ = get_prob.main(rerun=False) \n",
    "\n",
    "    # For each key=row_idx and val=prob_array, convert the inferred probabilities into emission.\n",
    "    for key, val in emission.items():\n",
    "        # Slice val to exclude the probabilities for background and silence.\n",
    "        if scale == True:\n",
    "            log_prob = np.where(val > 0, np.log(val), -np.inf)   # Get the log probabilities. \n",
    "            log_prob = log_prob[:-2]  # Exclude the background and silence in the emission probability calculation. \n",
    "            emission[key] = [log_prob-prior_vector]  # Divide by prior vector in the log space. \n",
    "        else:\n",
    "            emission[key] = [val] \n",
    "\n",
    "    emission_df = pd.DataFrame.from_dict(emission, orient='index', columns=['Emission']) \n",
    "    return emission_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_vector, _ = get_prob.main(rerun=True)\n",
    "estimate_prob = infer_probabilities(loader_test, model)\n",
    "emission_data = find_emission(loader_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(emission_data.iloc[0]['Emission'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting estimated probabilities on test set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5.173344e-17, 6.120392e-23, 2.0605932e-11, 9.465932e-12, 5.3322256e-06, 3.0784056e-05, 1.0712865e-20, 7.5062485e-07, 4.8062308e-35, 2.3023976e-13, 1.8673664e-07, 1.423909e-28, 0.53661686, 0.46334612]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2.7787693e-17, 9.537536e-24, 1.0677138e-11, 3.5048791e-12, 4.688974e-06, 2.5838719e-05, 5.8799286e-21, 1.5398612e-06, 2.1962397e-35, 1.4828275e-13, 2.027408e-07, 9.757805e-29, 0.71491474, 0.28505307]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[6.998184e-17, 7.781263e-24, 1.3595965e-11, 4.856749e-12, 6.3809853e-06, 1.2101964e-05, 9.752834e-21, 5.6644167e-06, 5.01677e-35, 5.2787706e-13, 9.4420267e-07, 2.2619855e-28, 0.7674287, 0.23254623]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2.5042545e-16, 1.7854215e-23, 6.291111e-12, 6.859706e-12, 1.0774825e-05, 4.0137293e-06, 5.342014e-21, 2.918402e-06, 1.5437594e-35, 2.6352462e-12, 4.096724e-06, 1.7958405e-28, 0.6176022, 0.3823759]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2.6210614e-16, 1.2530076e-22, 1.0357863e-11, 1.4791376e-11, 8.680606e-06, 7.376133e-06, 8.400631e-21, 1.5381328e-06, 3.153503e-35, 3.3971179e-12, 2.0572247e-06, 5.00163e-28, 0.3908442, 0.6091361]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>[8.6517884e-17, 1.4219562e-24, 3.6439518e-11, 2.4013114e-12, 6.3889743e-06, 1.0419658e-05, 1.3711779e-20, 7.3334313e-06, 1.3583143e-34, 8.7380386e-14, 1.4049484e-06, 2.614563e-29, 0.9301868, 0.06978762]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>[6.585328e-17, 1.7821863e-25, 6.731849e-12, 6.118342e-13, 7.818898e-06, 3.3083938e-06, 1.4325543e-21, 2.211141e-06, 2.8357356e-36, 6.9645834e-14, 1.5368756e-06, 1.2047304e-30, 0.92814225, 0.07184287]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>[4.821921e-17, 5.0479286e-27, 1.4460076e-12, 8.936295e-14, 8.59002e-06, 5.934953e-07, 3.1998049e-22, 1.2487617e-06, 2.875243e-37, 2.7855913e-14, 1.1575687e-06, 5.4721707e-32, 0.9761346, 0.02385378]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>[1.2331175e-17, 4.208773e-27, 1.1492836e-11, 1.5196304e-13, 3.5171854e-06, 1.8428162e-06, 2.690167e-21, 2.991768e-06, 1.2464048e-35, 2.565094e-15, 1.5951083e-07, 1.0977122e-31, 0.991508, 0.008483543]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>[7.503677e-18, 6.371372e-26, 1.2380999e-11, 5.03805e-13, 3.1350112e-06, 7.807253e-06, 1.1529565e-21, 1.8045707e-06, 1.7751453e-36, 6.9349078e-15, 1.9459016e-07, 2.8873933e-31, 0.9415966, 0.058390453]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                       Emission\n",
       "0      [5.173344e-17, 6.120392e-23, 2.0605932e-11, 9.465932e-12, 5.3322256e-06, 3.0784056e-05, 1.0712865e-20, 7.5062485e-07, 4.8062308e-35, 2.3023976e-13, 1.8673664e-07, 1.423909e-28, 0.53661686, 0.46334612]\n",
       "1      [2.7787693e-17, 9.537536e-24, 1.0677138e-11, 3.5048791e-12, 4.688974e-06, 2.5838719e-05, 5.8799286e-21, 1.5398612e-06, 2.1962397e-35, 1.4828275e-13, 2.027408e-07, 9.757805e-29, 0.71491474, 0.28505307]\n",
       "2         [6.998184e-17, 7.781263e-24, 1.3595965e-11, 4.856749e-12, 6.3809853e-06, 1.2101964e-05, 9.752834e-21, 5.6644167e-06, 5.01677e-35, 5.2787706e-13, 9.4420267e-07, 2.2619855e-28, 0.7674287, 0.23254623]\n",
       "3         [2.5042545e-16, 1.7854215e-23, 6.291111e-12, 6.859706e-12, 1.0774825e-05, 4.0137293e-06, 5.342014e-21, 2.918402e-06, 1.5437594e-35, 2.6352462e-12, 4.096724e-06, 1.7958405e-28, 0.6176022, 0.3823759]\n",
       "4          [2.6210614e-16, 1.2530076e-22, 1.0357863e-11, 1.4791376e-11, 8.680606e-06, 7.376133e-06, 8.400631e-21, 1.5381328e-06, 3.153503e-35, 3.3971179e-12, 2.0572247e-06, 5.00163e-28, 0.3908442, 0.6091361]\n",
       "..                                                                                                                                                                                                          ...\n",
       "402  [8.6517884e-17, 1.4219562e-24, 3.6439518e-11, 2.4013114e-12, 6.3889743e-06, 1.0419658e-05, 1.3711779e-20, 7.3334313e-06, 1.3583143e-34, 8.7380386e-14, 1.4049484e-06, 2.614563e-29, 0.9301868, 0.06978762]\n",
       "403     [6.585328e-17, 1.7821863e-25, 6.731849e-12, 6.118342e-13, 7.818898e-06, 3.3083938e-06, 1.4325543e-21, 2.211141e-06, 2.8357356e-36, 6.9645834e-14, 1.5368756e-06, 1.2047304e-30, 0.92814225, 0.07184287]\n",
       "404       [4.821921e-17, 5.0479286e-27, 1.4460076e-12, 8.936295e-14, 8.59002e-06, 5.934953e-07, 3.1998049e-22, 1.2487617e-06, 2.875243e-37, 2.7855913e-14, 1.1575687e-06, 5.4721707e-32, 0.9761346, 0.02385378]\n",
       "405     [1.2331175e-17, 4.208773e-27, 1.1492836e-11, 1.5196304e-13, 3.5171854e-06, 1.8428162e-06, 2.690167e-21, 2.991768e-06, 1.2464048e-35, 2.565094e-15, 1.5951083e-07, 1.0977122e-31, 0.991508, 0.008483543]\n",
       "406     [7.503677e-18, 6.371372e-26, 1.2380999e-11, 5.03805e-13, 3.1350112e-06, 7.807253e-06, 1.1529565e-21, 1.8045707e-06, 1.7751453e-36, 6.9349078e-15, 1.9459016e-07, 2.8873933e-31, 0.9415966, 0.058390453]\n",
       "\n",
       "[407 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def path_to_emission(model, file_path_wav: str, file_path_phn: str):\n",
    "    '''\n",
    "    Given the path of a file, get the emission probabilities.\n",
    "    Args:\n",
    "        model: DNN Model\n",
    "        file_path_vaw: Path of the audio file as a string.\n",
    "        file_path_phn: file path for the phonemes.\n",
    "    Returns:\n",
    "        emit: pd.dataframe\n",
    "            Emission probabilities for each frame in the audio file.\n",
    "    '''\n",
    "    df_test = mfcc_label.prepare_data(file_path_phn,file_path_wav)\n",
    "    DNN_utils.column_str_to_numpy(df_test, 'mfcc')\n",
    "    DNN_utils.column_str_to_numpy(df_test, 'label')\n",
    "    # Convert dataframe into a loader so that torch can work with.\n",
    "    dataset_test = CustomDataset(df_test,train=False)\n",
    "    loader_test = DataLoader(dataset_test, batch_size=1,\n",
    "                        sampler=sampler.SequentialSampler(range(len(df_test))))\n",
    "\n",
    "    emission_data = find_emission(loader_test, model)\n",
    "    return emission_data\n",
    "    \n",
    "\n",
    "path_to_emission(saved_model,'timit/data/TRAIN/DR4/MDCD0/SX425.WAV','timit/data/TRAIN/DR4/MDCD0/SX425.PHN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission_all_paths(model, path_type: str = 'test'):\n",
    "    '''\n",
    "    Get emission probabilities for all data files by using a specified DNN model.\n",
    "    Args: \n",
    "        model: DNN model\n",
    "        path_type: 'test' or 'train'\n",
    "                    Specify the type of files to get the emission probabilities for. It can be 'test' or 'train'.\n",
    "    Returns:\n",
    "        data: dict\n",
    "            The emission data for each audio file.\n",
    "    '''\n",
    "    from joblib import dump\n",
    "    paths = load('processed_data/train_test_dataset_never.joblib')[path_type]\n",
    "    data = {}\n",
    "    for i in range(len(paths)):\n",
    "        file_path_wav, file_path_phn, file_path_word = paths[i]\n",
    "        emission_data = path_to_emission(model, file_path_wav, file_path_phn)\n",
    "        data[(file_path_wav, file_path_phn, file_path_word)] = emission_data\n",
    "        \n",
    "        # Save the data to a joblib file.\n",
    "        from joblib import dump\n",
    "        dump(data, \"processed_data/\"+path_type+\"_data_for_hmm.joblib\") \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For start 36960 and end 37360, there is no time-overlapping row.\n",
      "Caution: There is no time-overlapping rows for start 36960 and end 37360\n",
      "Getting estimated probabilities on test set\n",
      "For start 45760 and end 46160, there is no time-overlapping row.\n",
      "Caution: There is no time-overlapping rows for start 45760 and end 46160\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "For start 62960 and end 63360, there is no time-overlapping row.\n",
      "Caution: There is no time-overlapping rows for start 62960 and end 63360\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "For start 31760 and end 32160, there is no time-overlapping row.\n",
      "Caution: There is no time-overlapping rows for start 31760 and end 32160\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "For start 0 and end 400, there is no time-overlapping row.\n",
      "For start 80 and end 480, there is no time-overlapping row.\n",
      "For start 160 and end 560, there is no time-overlapping row.\n",
      "For start 240 and end 640, there is no time-overlapping row.\n",
      "For start 320 and end 720, there is no time-overlapping row.\n",
      "For start 400 and end 800, there is no time-overlapping row.\n",
      "For start 480 and end 880, there is no time-overlapping row.\n",
      "For start 560 and end 960, there is no time-overlapping row.\n",
      "For start 640 and end 1040, there is no time-overlapping row.\n",
      "For start 720 and end 1120, there is no time-overlapping row.\n",
      "For start 800 and end 1200, there is no time-overlapping row.\n",
      "For start 880 and end 1280, there is no time-overlapping row.\n",
      "For start 960 and end 1360, there is no time-overlapping row.\n",
      "For start 1040 and end 1440, there is no time-overlapping row.\n",
      "For start 1120 and end 1520, there is no time-overlapping row.\n",
      "For start 1200 and end 1600, there is no time-overlapping row.\n",
      "For start 1280 and end 1680, there is no time-overlapping row.\n",
      "For start 1360 and end 1760, there is no time-overlapping row.\n",
      "For start 1440 and end 1840, there is no time-overlapping row.\n",
      "For start 1520 and end 1920, there is no time-overlapping row.\n",
      "For start 1600 and end 2000, there is no time-overlapping row.\n",
      "For start 1680 and end 2080, there is no time-overlapping row.\n",
      "For start 1760 and end 2160, there is no time-overlapping row.\n",
      "For start 1840 and end 2240, there is no time-overlapping row.\n",
      "For start 1920 and end 2320, there is no time-overlapping row.\n",
      "For start 2000 and end 2400, there is no time-overlapping row.\n",
      "Caution: There is no time-overlapping rows for start 0 and end 400\n",
      "Caution: There is no time-overlapping rows for start 80 and end 480\n",
      "Caution: There is no time-overlapping rows for start 160 and end 560\n",
      "Caution: There is no time-overlapping rows for start 240 and end 640\n",
      "Caution: There is no time-overlapping rows for start 320 and end 720\n",
      "Caution: There is no time-overlapping rows for start 400 and end 800\n",
      "Caution: There is no time-overlapping rows for start 480 and end 880\n",
      "Caution: There is no time-overlapping rows for start 560 and end 960\n",
      "Caution: There is no time-overlapping rows for start 640 and end 1040\n",
      "Caution: There is no time-overlapping rows for start 720 and end 1120\n",
      "Caution: There is no time-overlapping rows for start 800 and end 1200\n",
      "Caution: There is no time-overlapping rows for start 880 and end 1280\n",
      "Caution: There is no time-overlapping rows for start 960 and end 1360\n",
      "Caution: There is no time-overlapping rows for start 1040 and end 1440\n",
      "Caution: There is no time-overlapping rows for start 1120 and end 1520\n",
      "Caution: There is no time-overlapping rows for start 1200 and end 1600\n",
      "Caution: There is no time-overlapping rows for start 1280 and end 1680\n",
      "Caution: There is no time-overlapping rows for start 1360 and end 1760\n",
      "Caution: There is no time-overlapping rows for start 1440 and end 1840\n",
      "Caution: There is no time-overlapping rows for start 1520 and end 1920\n",
      "Caution: There is no time-overlapping rows for start 1600 and end 2000\n",
      "Caution: There is no time-overlapping rows for start 1680 and end 2080\n",
      "Caution: There is no time-overlapping rows for start 1760 and end 2160\n",
      "Caution: There is no time-overlapping rows for start 1840 and end 2240\n",
      "Caution: There is no time-overlapping rows for start 1920 and end 2320\n",
      "Caution: There is no time-overlapping rows for start 2000 and end 2400\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "Getting estimated probabilities on test set\n",
      "For start 43840 and end 44240, there is no time-overlapping row.\n",
      "Caution: There is no time-overlapping rows for start 43840 and end 44240\n",
      "Getting estimated probabilities on test set\n",
      "For start 51600 and end 52000, there is no time-overlapping row.\n",
      "Caution: There is no time-overlapping rows for start 51600 and end 52000\n",
      "Getting estimated probabilities on test set\n",
      "For start 56240 and end 56640, there is no time-overlapping row.\n",
      "Caution: There is no time-overlapping rows for start 56240 and end 56640\n",
      "Getting estimated probabilities on test set\n"
     ]
    }
   ],
   "source": [
    "data = get_emission_all_paths(saved_model, path_type=\"test\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processed_data/test_data_DNN_to_HMM.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(data, \"processed_data/test_data_DNN_to_HMM.joblib\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data[('timit/data/TRAIN/DR2/FPJF0/SX146.WAV',\n",
    "  'timit/data/TRAIN/DR2/FPJF0/SX146.PHN',\n",
    "  'timit/data/TRAIN/DR2/FPJF0/SX146.WRD')]\n",
    ") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
